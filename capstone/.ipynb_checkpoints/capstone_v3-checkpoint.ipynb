{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f83e4f9",
   "metadata": {},
   "source": [
    "# Air Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e8446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from ftplib import FTP\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from datetime import datetime\n",
    "import concurrent.futures\n",
    "import time\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error  # if you're using this elsewhere in the script\n",
    "from tensorflow.keras.models import load_model  # Import the load_model function to load the trained LSTM model\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabb394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetched from 2015-04-01 to 2015-07-22\n",
      "Data fetched from 2015-07-23 to 2015-11-12\n",
      "Data fetched from 2015-11-13 to 2016-03-04\n",
      "Data fetched from 2016-03-05 to 2016-06-25\n",
      "Data fetched from 2016-06-26 to 2016-10-16\n",
      "Data fetched from 2016-10-17 to 2017-02-06\n",
      "Data fetched from 2017-02-07 to 2017-05-30\n",
      "Data fetched from 2017-05-31 to 2017-09-20\n",
      "Data fetched from 2017-09-21 to 2018-01-11\n",
      "Data fetched from 2018-01-12 to 2018-05-04\n",
      "Data fetched from 2018-05-05 to 2018-08-25\n",
      "Data fetched from 2018-08-26 to 2018-12-16\n",
      "Data fetched from 2018-12-17 to 2019-04-08\n",
      "Data fetched from 2019-04-09 to 2019-07-30\n",
      "Data fetched from 2019-07-31 to 2019-11-20\n",
      "Data fetched from 2019-11-21 to 2020-03-12\n",
      "Data fetched from 2020-03-13 to 2020-07-03\n",
      "Data fetched from 2020-07-04 to 2020-10-24\n",
      "Data fetched from 2020-10-25 to 2021-02-14\n",
      "Data fetched from 2021-02-15 to 2021-06-07\n",
      "Data fetched from 2021-06-08 to 2021-09-28\n",
      "Data fetched from 2021-09-29 to 2022-01-19\n",
      "Error fetching data: Error: 502 - The specified CGI application encountered an error and the server terminated the process.. Retrying...\n",
      "Data fetched from 2022-01-20 to 2022-05-12\n",
      "Error fetching data: Error: 502 - The specified CGI application encountered an error and the server terminated the process.. Retrying...\n",
      "Data fetched from 2022-05-13 to 2022-09-02\n",
      "Error fetching data: Error: 502 - The specified CGI application encountered an error and the server terminated the process.. Retrying...\n",
      "Data fetched from 2022-09-03 to 2022-12-24\n",
      "Error fetching data: Error: 502 - The specified CGI application encountered an error and the server terminated the process.. Retrying...\n",
      "Data fetched from 2022-12-25 to 2023-04-16\n",
      "Error fetching data: Error: 502 - The specified CGI application encountered an error and the server terminated the process.. Retrying...\n",
      "Data fetched from 2023-04-17 to 2023-08-07\n",
      "Error fetching data: Error: 502 - The specified CGI application encountered an error and the server terminated the process.. Retrying...\n",
      "Data fetched from 2023-08-08 to 2023-11-28\n",
      "Error fetching data: Error: 502 - The specified CGI application encountered an error and the server terminated the process.. Retrying...\n",
      "Data fetched from 2023-11-29 to 2024-03-20\n",
      "Error fetching data: Error: 502 - The specified CGI application encountered an error and the server terminated the process.. Retrying...\n",
      "Data fetched from 2024-03-21 to 2024-07-11\n",
      "Error fetching data: Error: 502 - The specified CGI application encountered an error and the server terminated the process.. Retrying...\n",
      "Data fetched from 2024-07-12 to 2024-10-22\n",
      "Air quality data collection completed at 2024-10-22 18:53:03.429409\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Define the base URL for the POST request\n",
    "url = 'https://data.airquality.nsw.gov.au/api/Data/get_Observations'\n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Define the initial start and end dates\n",
    "start_date = datetime.strptime(\"2015-04-01\", \"%Y-%m-%d\")\n",
    "end_date = datetime.today()  # End date is today\n",
    "max_chunk_days = 112  # Maximum number of days per API call\n",
    "retries = 3  # Retry attempts for failed iterations\n",
    "\n",
    "# Function to make the API request and process the data\n",
    "def process_iteration(start_date_str, end_date_str):\n",
    "    # Construct the payload for each chunk period\n",
    "    payload = {\n",
    "        \"Parameters\": [\"PM10\", \"PM2.5\", \"CO\", \"NH3\", \"NO\", \"NO2\", \"SO2\", \"OZONE\", \"TSPd\",\n",
    "                       \"RAIN\", \"SOLAR\", \"TEMP\", \"SD1\", \"WDR\", \"WSP\", \"Humid\", \"NEPH\"],                       \n",
    "        \"Sites\": [39],   # List of site IDs\n",
    "        \"StartDate\": start_date_str,  # Start date for the API request\n",
    "        \"EndDate\": end_date_str,      # End date for the API request\n",
    "        \"Categories\": [\"Averages\"],   \n",
    "        \"SubCategories\": [\"Hourly\"], \n",
    "        \"Frequency\": [\"Hourly Average\"]\n",
    "    }\n",
    "\n",
    "    # Set the headers for the request\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    # Make the POST request\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the response JSON and convert it to a DataFrame\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(data)\n",
    "        return df  # Return the DataFrame if successful\n",
    "    else:\n",
    "        # Raise an exception if the request failed\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "# Main function to handle fetching data across multiple time chunks\n",
    "def fetch_air_quality_data():\n",
    "    # List to store all the data frames fetched\n",
    "    data_frames = []\n",
    "    \n",
    "    # Reference the start_date and end_date within the function\n",
    "    global start_date, end_date\n",
    "\n",
    "    # Loop through the time range, fetching data for each chunk\n",
    "    while start_date < end_date:\n",
    "        start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "        end_date_chunk = start_date + timedelta(days=max_chunk_days)\n",
    "        \n",
    "        # Ensure that the end_date_chunk does not exceed today's date\n",
    "        if end_date_chunk > end_date:\n",
    "            end_date_chunk = end_date\n",
    "        \n",
    "        end_date_str = end_date_chunk.strftime(\"%Y-%m-%d\")\n",
    "        attempt = 0\n",
    "        \n",
    "        # Retry logic for making the API request\n",
    "        while attempt < retries:\n",
    "            try:\n",
    "                # Fetch and process data for the current date chunk\n",
    "                df = process_iteration(start_date_str, end_date_str)\n",
    "                data_frames.append(df)\n",
    "                print(f\"Data fetched from {start_date_str} to {end_date_str}\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                print(f\"Error fetching data: {e}. Retrying...\")\n",
    "                time.sleep(5)  # Sleep for 5 seconds before retrying\n",
    "\n",
    "        # Update start_date to the next day after the current chunk\n",
    "        start_date = end_date_chunk + timedelta(days=1)\n",
    "        time.sleep(2)  # Sleep between requests to avoid hitting rate limits\n",
    "\n",
    "    # Combine all the fetched data into a single DataFrame\n",
    "    if data_frames:\n",
    "        combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "        combined_df = combined_df.infer_objects()  # Ensure data types are inferred correctly\n",
    "        print(f\"Air quality data collection completed at {datetime.now()}\")\n",
    "    else:\n",
    "        print(\"No data was collected.\")\n",
    "\n",
    "    # Return the combined DataFrame\n",
    "    return combined_df\n",
    "\n",
    "# Run the data fetching function\n",
    "combined_df = fetch_air_quality_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded0bfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1246320 entries, 0 to 1246319\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count    Dtype  \n",
      "---  ------                --------------    -----  \n",
      " 0   Site_Id               1246320 non-null  int64  \n",
      " 1   Parameter             1246320 non-null  object \n",
      " 2   Date                  1246320 non-null  object \n",
      " 3   Hour                  1246320 non-null  int64  \n",
      " 4   HourDescription       1246320 non-null  object \n",
      " 5   Value                 1141679 non-null  float64\n",
      " 6   AirQualityCategory    381911 non-null   object \n",
      " 7   DeterminingPollutant  0 non-null        object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 76.1+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d3f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e1c3371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site_Id</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>HourDescription</th>\n",
       "      <th>Value</th>\n",
       "      <th>AirQualityCategory</th>\n",
       "      <th>DeterminingPollutant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>{'ParameterCode': 'CO', 'ParameterDescription'...</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>12 am - 1 am</td>\n",
       "      <td>0.754289</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>{'ParameterCode': 'HUMID', 'ParameterDescripti...</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>12 am - 1 am</td>\n",
       "      <td>94.199000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>{'ParameterCode': 'NEPH', 'ParameterDescriptio...</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>12 am - 1 am</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>{'ParameterCode': 'NO', 'ParameterDescription'...</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>12 am - 1 am</td>\n",
       "      <td>6.026604</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>{'ParameterCode': 'NO2', 'ParameterDescription...</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>12 am - 1 am</td>\n",
       "      <td>1.959503</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Site_Id                                          Parameter        Date  \\\n",
       "0       39  {'ParameterCode': 'CO', 'ParameterDescription'...  2015-04-01   \n",
       "1       39  {'ParameterCode': 'HUMID', 'ParameterDescripti...  2015-04-01   \n",
       "2       39  {'ParameterCode': 'NEPH', 'ParameterDescriptio...  2015-04-01   \n",
       "3       39  {'ParameterCode': 'NO', 'ParameterDescription'...  2015-04-01   \n",
       "4       39  {'ParameterCode': 'NO2', 'ParameterDescription...  2015-04-01   \n",
       "\n",
       "   Hour HourDescription      Value AirQualityCategory DeterminingPollutant  \n",
       "0     1    12 am - 1 am   0.754289               None                 None  \n",
       "1     1    12 am - 1 am  94.199000               None                 None  \n",
       "2     1    12 am - 1 am   0.232000               None                 None  \n",
       "3     1    12 am - 1 am   6.026604               None                 None  \n",
       "4     1    12 am - 1 am   1.959503               GOOD                 None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f010e144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    {'ParameterCode': 'CO', 'ParameterDescription'...\n",
      "1    {'ParameterCode': 'HUMID', 'ParameterDescripti...\n",
      "2    {'ParameterCode': 'NEPH', 'ParameterDescriptio...\n",
      "3    {'ParameterCode': 'NO', 'ParameterDescription'...\n",
      "4    {'ParameterCode': 'NO2', 'ParameterDescription...\n",
      "Name: Parameter, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check the structure of the 'Parameter' column to ensure it's consistent\n",
    "print(df['Parameter'].head())  # Check if this is indeed a dictionary or JSON-like\n",
    "\n",
    "# Step 1: Extract 'ParameterCode' and 'ParameterDescription' from the 'Parameter' column\n",
    "# We handle cases where 'Parameter' might not be a dictionary\n",
    "df['ParameterCode'] = df['Parameter'].apply(lambda x: x.get('ParameterCode') if isinstance(x, dict) else None)\n",
    "df['ParameterDescription'] = df['Parameter'].apply(lambda x: x.get('ParameterDescription') if isinstance(x, dict) else None)\n",
    "\n",
    "# Step 2: Now pivot the DataFrame to have one row per time observation, with multiple columns\n",
    "df_wide = df.pivot_table(index=['Site_Id', 'Date', 'Hour', 'HourDescription'],\n",
    "                         columns='ParameterCode', \n",
    "                         values='Value', \n",
    "                         aggfunc='first').reset_index()\n",
    "\n",
    "# Optional: Flatten the MultiIndex columns if necessary\n",
    "df_wide.columns = [col if not isinstance(col, tuple) else col[1] for col in df_wide.columns]\n",
    "\n",
    "# Step 3: Display the wide-format DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79cf8c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site_Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>HourDescription</th>\n",
       "      <th>CO</th>\n",
       "      <th>HUMID</th>\n",
       "      <th>NEPH</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>OZONE</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>SD1</th>\n",
       "      <th>SO2</th>\n",
       "      <th>SOLAR</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>12 am - 1 am</td>\n",
       "      <td>0.754289</td>\n",
       "      <td>94.199</td>\n",
       "      <td>0.232</td>\n",
       "      <td>6.026604</td>\n",
       "      <td>1.959503</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>13.925</td>\n",
       "      <td>7.381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.103</td>\n",
       "      <td>0.096339</td>\n",
       "      <td>-13.130</td>\n",
       "      <td>17.708</td>\n",
       "      <td>10.815</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1 am - 2 am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.513</td>\n",
       "      <td>0.196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.096</td>\n",
       "      <td>5.359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.835</td>\n",
       "      <td>18.285</td>\n",
       "      <td>325.715</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>3</td>\n",
       "      <td>2 am - 3 am</td>\n",
       "      <td>0.430155</td>\n",
       "      <td>95.974</td>\n",
       "      <td>0.177</td>\n",
       "      <td>1.928971</td>\n",
       "      <td>1.746824</td>\n",
       "      <td>0.129325</td>\n",
       "      <td>3.914</td>\n",
       "      <td>2.542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.922</td>\n",
       "      <td>0.041979</td>\n",
       "      <td>-11.332</td>\n",
       "      <td>17.876</td>\n",
       "      <td>270.408</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3 am - 4 am</td>\n",
       "      <td>0.407481</td>\n",
       "      <td>96.580</td>\n",
       "      <td>0.218</td>\n",
       "      <td>2.555419</td>\n",
       "      <td>1.651218</td>\n",
       "      <td>0.056325</td>\n",
       "      <td>3.088</td>\n",
       "      <td>5.263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.073</td>\n",
       "      <td>0.064485</td>\n",
       "      <td>-11.606</td>\n",
       "      <td>17.231</td>\n",
       "      <td>261.068</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>5</td>\n",
       "      <td>4 am - 5 am</td>\n",
       "      <td>0.369815</td>\n",
       "      <td>97.003</td>\n",
       "      <td>0.198</td>\n",
       "      <td>2.426823</td>\n",
       "      <td>1.576204</td>\n",
       "      <td>0.047325</td>\n",
       "      <td>16.753</td>\n",
       "      <td>9.678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.759</td>\n",
       "      <td>0.057291</td>\n",
       "      <td>-11.636</td>\n",
       "      <td>17.277</td>\n",
       "      <td>23.419</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Site_Id        Date  Hour HourDescription        CO   HUMID   NEPH  \\\n",
       "0       39  2015-04-01     1    12 am - 1 am  0.754289  94.199  0.232   \n",
       "1       39  2015-04-01     2     1 am - 2 am       NaN  94.513  0.196   \n",
       "2       39  2015-04-01     3     2 am - 3 am  0.430155  95.974  0.177   \n",
       "3       39  2015-04-01     4     3 am - 4 am  0.407481  96.580  0.218   \n",
       "4       39  2015-04-01     5     4 am - 5 am  0.369815  97.003  0.198   \n",
       "\n",
       "         NO       NO2     OZONE    PM10  PM2.5  RAIN      SD1       SO2  \\\n",
       "0  6.026604  1.959503  0.049300  13.925  7.381   NaN  108.103  0.096339   \n",
       "1       NaN       NaN       NaN  18.096  5.359   NaN   59.602       NaN   \n",
       "2  1.928971  1.746824  0.129325   3.914  2.542   NaN   77.922  0.041979   \n",
       "3  2.555419  1.651218  0.056325   3.088  5.263   NaN   77.073  0.064485   \n",
       "4  2.426823  1.576204  0.047325  16.753  9.678   NaN   95.759  0.057291   \n",
       "\n",
       "    SOLAR    TEMP      WDR    WSP  \n",
       "0 -13.130  17.708   10.815  0.130  \n",
       "1 -12.835  18.285  325.715  0.605  \n",
       "2 -11.332  17.876  270.408  0.260  \n",
       "3 -11.606  17.231  261.068  0.109  \n",
       "4 -11.636  17.277   23.419  0.084  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e91c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79821 entries, 0 to 79820\n",
      "Data columns (total 19 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Site_Id          79821 non-null  int64  \n",
      " 1   Date             79821 non-null  object \n",
      " 2   Hour             79821 non-null  int64  \n",
      " 3   HourDescription  79821 non-null  object \n",
      " 4   CO               74594 non-null  float64\n",
      " 5   HUMID            79722 non-null  float64\n",
      " 6   NEPH             79155 non-null  float64\n",
      " 7   NO               74934 non-null  float64\n",
      " 8   NO2              74935 non-null  float64\n",
      " 9   OZONE            75419 non-null  float64\n",
      " 10  PM10             78806 non-null  float64\n",
      " 11  PM2.5            77992 non-null  float64\n",
      " 12  RAIN             54139 non-null  float64\n",
      " 13  SD1              79318 non-null  float64\n",
      " 14  SO2              74759 non-null  float64\n",
      " 15  SOLAR            79485 non-null  float64\n",
      " 16  TEMP             79787 non-null  float64\n",
      " 17  WDR              79318 non-null  float64\n",
      " 18  WSP              79316 non-null  float64\n",
      "dtypes: float64(15), int64(2), object(2)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_wide.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ac086e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site_Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>HourDescription</th>\n",
       "      <th>CO</th>\n",
       "      <th>HUMID</th>\n",
       "      <th>NEPH</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>OZONE</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>SD1</th>\n",
       "      <th>SO2</th>\n",
       "      <th>SOLAR</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>12 am - 1 am</td>\n",
       "      <td>0.754289</td>\n",
       "      <td>94.199</td>\n",
       "      <td>0.232</td>\n",
       "      <td>6.026604</td>\n",
       "      <td>1.959503</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>13.925</td>\n",
       "      <td>7.381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.103</td>\n",
       "      <td>0.096339</td>\n",
       "      <td>-13.130</td>\n",
       "      <td>17.708</td>\n",
       "      <td>10.815</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1 am - 2 am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.513</td>\n",
       "      <td>0.196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.096</td>\n",
       "      <td>5.359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.835</td>\n",
       "      <td>18.285</td>\n",
       "      <td>325.715</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>3</td>\n",
       "      <td>2 am - 3 am</td>\n",
       "      <td>0.430155</td>\n",
       "      <td>95.974</td>\n",
       "      <td>0.177</td>\n",
       "      <td>1.928971</td>\n",
       "      <td>1.746824</td>\n",
       "      <td>0.129325</td>\n",
       "      <td>3.914</td>\n",
       "      <td>2.542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.922</td>\n",
       "      <td>0.041979</td>\n",
       "      <td>-11.332</td>\n",
       "      <td>17.876</td>\n",
       "      <td>270.408</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3 am - 4 am</td>\n",
       "      <td>0.407481</td>\n",
       "      <td>96.580</td>\n",
       "      <td>0.218</td>\n",
       "      <td>2.555419</td>\n",
       "      <td>1.651218</td>\n",
       "      <td>0.056325</td>\n",
       "      <td>3.088</td>\n",
       "      <td>5.263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.073</td>\n",
       "      <td>0.064485</td>\n",
       "      <td>-11.606</td>\n",
       "      <td>17.231</td>\n",
       "      <td>261.068</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>5</td>\n",
       "      <td>4 am - 5 am</td>\n",
       "      <td>0.369815</td>\n",
       "      <td>97.003</td>\n",
       "      <td>0.198</td>\n",
       "      <td>2.426823</td>\n",
       "      <td>1.576204</td>\n",
       "      <td>0.047325</td>\n",
       "      <td>16.753</td>\n",
       "      <td>9.678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.759</td>\n",
       "      <td>0.057291</td>\n",
       "      <td>-11.636</td>\n",
       "      <td>17.277</td>\n",
       "      <td>23.419</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Site_Id        Date  Hour HourDescription        CO   HUMID   NEPH  \\\n",
       "0       39  2015-04-01     1    12 am - 1 am  0.754289  94.199  0.232   \n",
       "1       39  2015-04-01     2     1 am - 2 am       NaN  94.513  0.196   \n",
       "2       39  2015-04-01     3     2 am - 3 am  0.430155  95.974  0.177   \n",
       "3       39  2015-04-01     4     3 am - 4 am  0.407481  96.580  0.218   \n",
       "4       39  2015-04-01     5     4 am - 5 am  0.369815  97.003  0.198   \n",
       "\n",
       "         NO       NO2     OZONE    PM10  PM2.5  RAIN      SD1       SO2  \\\n",
       "0  6.026604  1.959503  0.049300  13.925  7.381   NaN  108.103  0.096339   \n",
       "1       NaN       NaN       NaN  18.096  5.359   NaN   59.602       NaN   \n",
       "2  1.928971  1.746824  0.129325   3.914  2.542   NaN   77.922  0.041979   \n",
       "3  2.555419  1.651218  0.056325   3.088  5.263   NaN   77.073  0.064485   \n",
       "4  2.426823  1.576204  0.047325  16.753  9.678   NaN   95.759  0.057291   \n",
       "\n",
       "    SOLAR    TEMP      WDR    WSP  \n",
       "0 -13.130  17.708   10.815  0.130  \n",
       "1 -12.835  18.285  325.715  0.605  \n",
       "2 -11.332  17.876  270.408  0.260  \n",
       "3 -11.606  17.231  261.068  0.109  \n",
       "4 -11.636  17.277   23.419  0.084  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide.head()  # Check for NaNs at the top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34e25b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Site_Id        Date  Hour HourDescription        CO   HUMID   NEPH  \\\n",
      "0           39  2015-04-01     1    12 am - 1 am  0.754289  94.199  0.232   \n",
      "1           39  2015-04-01     2     1 am - 2 am  0.754289  94.513  0.196   \n",
      "2           39  2015-04-01     3     2 am - 3 am  0.430155  95.974  0.177   \n",
      "3           39  2015-04-01     4     3 am - 4 am  0.407481  96.580  0.218   \n",
      "4           39  2015-04-01     5     4 am - 5 am  0.369815  97.003  0.198   \n",
      "...        ...         ...   ...             ...       ...     ...    ...   \n",
      "79816       39  2024-10-21    20     7 pm - 8 pm  0.195528  67.602  0.147   \n",
      "79817       39  2024-10-21    21     8 pm - 9 pm  0.179877  66.455  0.137   \n",
      "79818       39  2024-10-21    22    9 pm - 10 pm  0.179647  66.264  0.123   \n",
      "79819       39  2024-10-21    23   10 pm - 11 pm  0.191574  73.396  0.158   \n",
      "79820       39  2024-10-21    24   11 pm - 12 am  0.247996  80.383  0.238   \n",
      "\n",
      "             NO       NO2     OZONE    PM10  PM2.5  RAIN      SD1       SO2  \\\n",
      "0      6.026604  1.959503  0.049300  13.925  7.381   0.4  108.103  0.096339   \n",
      "1      6.026604  1.959503  0.049300  18.096  5.359   0.4   59.602  0.096339   \n",
      "2      1.928971  1.746824  0.129325   3.914  2.542   0.4   77.922  0.041979   \n",
      "3      2.555419  1.651218  0.056325   3.088  5.263   0.4   77.073  0.064485   \n",
      "4      2.426823  1.576204  0.047325  16.753  9.678   0.4   95.759  0.057291   \n",
      "...         ...       ...       ...     ...    ...   ...      ...       ...   \n",
      "79816 -0.060811  0.185808  2.690700  19.061  6.988   0.0   19.862  0.011072   \n",
      "79817 -0.036812  0.287628  2.612200  12.710  1.425   0.0   18.941  0.011571   \n",
      "79818 -0.074438  0.053301  2.840200  19.583  0.452   0.0   18.874 -0.000199   \n",
      "79819 -0.070675 -0.029191  2.808700  25.113  4.050   0.0   28.669 -0.015761   \n",
      "79820 -0.058981  0.165882  2.194300  18.734  5.011   0.0   85.029  0.016559   \n",
      "\n",
      "        SOLAR    TEMP      WDR    WSP  \n",
      "0     -13.130  17.708   10.815  0.130  \n",
      "1     -12.835  18.285  325.715  0.605  \n",
      "2     -11.332  17.876  270.408  0.260  \n",
      "3     -11.606  17.231  261.068  0.109  \n",
      "4     -11.636  17.277   23.419  0.084  \n",
      "...       ...     ...      ...    ...  \n",
      "79816  -8.006  16.707  186.470  2.903  \n",
      "79817  -7.524  16.675  183.586  3.167  \n",
      "79818  -6.826  16.678  192.818  2.290  \n",
      "79819  -6.506  16.558  189.327  2.547  \n",
      "79820  -7.623  15.488  203.092  0.275  \n",
      "\n",
      "[79821 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fill NaNs at the edges with forward and backward filling\n",
    "df_wide.fillna(method='ffill', inplace=True)\n",
    "df_wide.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Then apply interpolation to fill NaNs between rows\n",
    "df_wide.interpolate(method='linear', axis=0, inplace=True)\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "print(df_wide)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "290b8806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79821 entries, 0 to 79820\n",
      "Data columns (total 19 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Site_Id          79821 non-null  int64  \n",
      " 1   Date             79821 non-null  object \n",
      " 2   Hour             79821 non-null  int64  \n",
      " 3   HourDescription  79821 non-null  object \n",
      " 4   CO               79821 non-null  float64\n",
      " 5   HUMID            79821 non-null  float64\n",
      " 6   NEPH             79821 non-null  float64\n",
      " 7   NO               79821 non-null  float64\n",
      " 8   NO2              79821 non-null  float64\n",
      " 9   OZONE            79821 non-null  float64\n",
      " 10  PM10             79821 non-null  float64\n",
      " 11  PM2.5            79821 non-null  float64\n",
      " 12  RAIN             79821 non-null  float64\n",
      " 13  SD1              79821 non-null  float64\n",
      " 14  SO2              79821 non-null  float64\n",
      " 15  SOLAR            79821 non-null  float64\n",
      " 16  TEMP             79821 non-null  float64\n",
      " 17  WDR              79821 non-null  float64\n",
      " 18  WSP              79821 non-null  float64\n",
      "dtypes: float64(15), int64(2), object(2)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_wide.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d39c412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site_Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>HourDescription</th>\n",
       "      <th>CO</th>\n",
       "      <th>HUMID</th>\n",
       "      <th>NEPH</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>OZONE</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>SD1</th>\n",
       "      <th>SO2</th>\n",
       "      <th>SOLAR</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>12 am - 1 am</td>\n",
       "      <td>0.754289</td>\n",
       "      <td>94.199</td>\n",
       "      <td>0.232</td>\n",
       "      <td>6.026604</td>\n",
       "      <td>1.959503</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>13.925</td>\n",
       "      <td>7.381</td>\n",
       "      <td>0.4</td>\n",
       "      <td>108.103</td>\n",
       "      <td>0.096339</td>\n",
       "      <td>-13.130</td>\n",
       "      <td>17.708</td>\n",
       "      <td>10.815</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1 am - 2 am</td>\n",
       "      <td>0.754289</td>\n",
       "      <td>94.513</td>\n",
       "      <td>0.196</td>\n",
       "      <td>6.026604</td>\n",
       "      <td>1.959503</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>18.096</td>\n",
       "      <td>5.359</td>\n",
       "      <td>0.4</td>\n",
       "      <td>59.602</td>\n",
       "      <td>0.096339</td>\n",
       "      <td>-12.835</td>\n",
       "      <td>18.285</td>\n",
       "      <td>325.715</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>3</td>\n",
       "      <td>2 am - 3 am</td>\n",
       "      <td>0.430155</td>\n",
       "      <td>95.974</td>\n",
       "      <td>0.177</td>\n",
       "      <td>1.928971</td>\n",
       "      <td>1.746824</td>\n",
       "      <td>0.129325</td>\n",
       "      <td>3.914</td>\n",
       "      <td>2.542</td>\n",
       "      <td>0.4</td>\n",
       "      <td>77.922</td>\n",
       "      <td>0.041979</td>\n",
       "      <td>-11.332</td>\n",
       "      <td>17.876</td>\n",
       "      <td>270.408</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3 am - 4 am</td>\n",
       "      <td>0.407481</td>\n",
       "      <td>96.580</td>\n",
       "      <td>0.218</td>\n",
       "      <td>2.555419</td>\n",
       "      <td>1.651218</td>\n",
       "      <td>0.056325</td>\n",
       "      <td>3.088</td>\n",
       "      <td>5.263</td>\n",
       "      <td>0.4</td>\n",
       "      <td>77.073</td>\n",
       "      <td>0.064485</td>\n",
       "      <td>-11.606</td>\n",
       "      <td>17.231</td>\n",
       "      <td>261.068</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>5</td>\n",
       "      <td>4 am - 5 am</td>\n",
       "      <td>0.369815</td>\n",
       "      <td>97.003</td>\n",
       "      <td>0.198</td>\n",
       "      <td>2.426823</td>\n",
       "      <td>1.576204</td>\n",
       "      <td>0.047325</td>\n",
       "      <td>16.753</td>\n",
       "      <td>9.678</td>\n",
       "      <td>0.4</td>\n",
       "      <td>95.759</td>\n",
       "      <td>0.057291</td>\n",
       "      <td>-11.636</td>\n",
       "      <td>17.277</td>\n",
       "      <td>23.419</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Site_Id        Date  Hour HourDescription        CO   HUMID   NEPH  \\\n",
       "0       39  2015-04-01     1    12 am - 1 am  0.754289  94.199  0.232   \n",
       "1       39  2015-04-01     2     1 am - 2 am  0.754289  94.513  0.196   \n",
       "2       39  2015-04-01     3     2 am - 3 am  0.430155  95.974  0.177   \n",
       "3       39  2015-04-01     4     3 am - 4 am  0.407481  96.580  0.218   \n",
       "4       39  2015-04-01     5     4 am - 5 am  0.369815  97.003  0.198   \n",
       "\n",
       "         NO       NO2     OZONE    PM10  PM2.5  RAIN      SD1       SO2  \\\n",
       "0  6.026604  1.959503  0.049300  13.925  7.381   0.4  108.103  0.096339   \n",
       "1  6.026604  1.959503  0.049300  18.096  5.359   0.4   59.602  0.096339   \n",
       "2  1.928971  1.746824  0.129325   3.914  2.542   0.4   77.922  0.041979   \n",
       "3  2.555419  1.651218  0.056325   3.088  5.263   0.4   77.073  0.064485   \n",
       "4  2.426823  1.576204  0.047325  16.753  9.678   0.4   95.759  0.057291   \n",
       "\n",
       "    SOLAR    TEMP      WDR    WSP  \n",
       "0 -13.130  17.708   10.815  0.130  \n",
       "1 -12.835  18.285  325.715  0.605  \n",
       "2 -11.332  17.876  270.408  0.260  \n",
       "3 -11.606  17.231  261.068  0.109  \n",
       "4 -11.636  17.277   23.419  0.084  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66a67411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/br/kn0p5yrn6d771z_m2v7qll780000gp/T/ipykernel_73596/1143397080.py:20: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the count of NaN values by time (i.e., how many NaNs per day)\n",
    "nan_by_time = df_wide.isna().sum(axis=1)\n",
    "\n",
    "# Plot the NaN counts over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(nan_by_time, color='red', marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of NaN values')\n",
    "plt.title('Number of NaN Values Over Time in daily_aggregated_mean DataFrame')\n",
    "\n",
    "# Rotating x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0606e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site_Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>HourDescription</th>\n",
       "      <th>CO</th>\n",
       "      <th>HUMID</th>\n",
       "      <th>NEPH</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>OZONE</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>SD1</th>\n",
       "      <th>SO2</th>\n",
       "      <th>SOLAR</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WDR</th>\n",
       "      <th>WSP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-04-01 01:00:00</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>12 am - 1 am</td>\n",
       "      <td>0.754289</td>\n",
       "      <td>94.199</td>\n",
       "      <td>0.232</td>\n",
       "      <td>6.026604</td>\n",
       "      <td>1.959503</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>13.925</td>\n",
       "      <td>7.381</td>\n",
       "      <td>0.4</td>\n",
       "      <td>108.103</td>\n",
       "      <td>0.096339</td>\n",
       "      <td>-13.130</td>\n",
       "      <td>17.708</td>\n",
       "      <td>10.815</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-01 02:00:00</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1 am - 2 am</td>\n",
       "      <td>0.754289</td>\n",
       "      <td>94.513</td>\n",
       "      <td>0.196</td>\n",
       "      <td>6.026604</td>\n",
       "      <td>1.959503</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>18.096</td>\n",
       "      <td>5.359</td>\n",
       "      <td>0.4</td>\n",
       "      <td>59.602</td>\n",
       "      <td>0.096339</td>\n",
       "      <td>-12.835</td>\n",
       "      <td>18.285</td>\n",
       "      <td>325.715</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-01 03:00:00</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>3</td>\n",
       "      <td>2 am - 3 am</td>\n",
       "      <td>0.430155</td>\n",
       "      <td>95.974</td>\n",
       "      <td>0.177</td>\n",
       "      <td>1.928971</td>\n",
       "      <td>1.746824</td>\n",
       "      <td>0.129325</td>\n",
       "      <td>3.914</td>\n",
       "      <td>2.542</td>\n",
       "      <td>0.4</td>\n",
       "      <td>77.922</td>\n",
       "      <td>0.041979</td>\n",
       "      <td>-11.332</td>\n",
       "      <td>17.876</td>\n",
       "      <td>270.408</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-01 04:00:00</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3 am - 4 am</td>\n",
       "      <td>0.407481</td>\n",
       "      <td>96.580</td>\n",
       "      <td>0.218</td>\n",
       "      <td>2.555419</td>\n",
       "      <td>1.651218</td>\n",
       "      <td>0.056325</td>\n",
       "      <td>3.088</td>\n",
       "      <td>5.263</td>\n",
       "      <td>0.4</td>\n",
       "      <td>77.073</td>\n",
       "      <td>0.064485</td>\n",
       "      <td>-11.606</td>\n",
       "      <td>17.231</td>\n",
       "      <td>261.068</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-01 05:00:00</th>\n",
       "      <td>39</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>5</td>\n",
       "      <td>4 am - 5 am</td>\n",
       "      <td>0.369815</td>\n",
       "      <td>97.003</td>\n",
       "      <td>0.198</td>\n",
       "      <td>2.426823</td>\n",
       "      <td>1.576204</td>\n",
       "      <td>0.047325</td>\n",
       "      <td>16.753</td>\n",
       "      <td>9.678</td>\n",
       "      <td>0.4</td>\n",
       "      <td>95.759</td>\n",
       "      <td>0.057291</td>\n",
       "      <td>-11.636</td>\n",
       "      <td>17.277</td>\n",
       "      <td>23.419</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Site_Id        Date  Hour HourDescription        CO  \\\n",
       "datetime                                                                   \n",
       "2015-04-01 01:00:00       39  2015-04-01     1    12 am - 1 am  0.754289   \n",
       "2015-04-01 02:00:00       39  2015-04-01     2     1 am - 2 am  0.754289   \n",
       "2015-04-01 03:00:00       39  2015-04-01     3     2 am - 3 am  0.430155   \n",
       "2015-04-01 04:00:00       39  2015-04-01     4     3 am - 4 am  0.407481   \n",
       "2015-04-01 05:00:00       39  2015-04-01     5     4 am - 5 am  0.369815   \n",
       "\n",
       "                      HUMID   NEPH        NO       NO2     OZONE    PM10  \\\n",
       "datetime                                                                   \n",
       "2015-04-01 01:00:00  94.199  0.232  6.026604  1.959503  0.049300  13.925   \n",
       "2015-04-01 02:00:00  94.513  0.196  6.026604  1.959503  0.049300  18.096   \n",
       "2015-04-01 03:00:00  95.974  0.177  1.928971  1.746824  0.129325   3.914   \n",
       "2015-04-01 04:00:00  96.580  0.218  2.555419  1.651218  0.056325   3.088   \n",
       "2015-04-01 05:00:00  97.003  0.198  2.426823  1.576204  0.047325  16.753   \n",
       "\n",
       "                     PM2.5  RAIN      SD1       SO2   SOLAR    TEMP      WDR  \\\n",
       "datetime                                                                       \n",
       "2015-04-01 01:00:00  7.381   0.4  108.103  0.096339 -13.130  17.708   10.815   \n",
       "2015-04-01 02:00:00  5.359   0.4   59.602  0.096339 -12.835  18.285  325.715   \n",
       "2015-04-01 03:00:00  2.542   0.4   77.922  0.041979 -11.332  17.876  270.408   \n",
       "2015-04-01 04:00:00  5.263   0.4   77.073  0.064485 -11.606  17.231  261.068   \n",
       "2015-04-01 05:00:00  9.678   0.4   95.759  0.057291 -11.636  17.277   23.419   \n",
       "\n",
       "                       WSP  \n",
       "datetime                    \n",
       "2015-04-01 01:00:00  0.130  \n",
       "2015-04-01 02:00:00  0.605  \n",
       "2015-04-01 03:00:00  0.260  \n",
       "2015-04-01 04:00:00  0.109  \n",
       "2015-04-01 05:00:00  0.084  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide['datetime'] = pd.to_datetime(df_wide['Date']) + pd.to_timedelta(df_wide['Hour'], unit='h')\n",
    "\n",
    "# Set 'datetime' as the index\n",
    "df_wide.set_index('datetime', inplace=True)\n",
    "df_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4796b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the aggregation rules for each parameter\n",
    "aggregation_rules_mean = {\n",
    "    'CO': 'mean',           # Daily mean for CO\n",
    "    'HUMID': 'mean',        # Daily mean for Humidity\n",
    "    'NEPH': 'mean',         # Daily mean for NEPH\n",
    "    'NO': 'mean',           # Daily mean for NO\n",
    "    'NO2': 'mean',          # Daily mean for NO2\n",
    "    'OZONE': 'mean',        # Daily mean for Ozone\n",
    "    'SO2': 'mean',          # Daily mean for SO2\n",
    "    'PM10': 'mean',         # Daily mean for PM10\n",
    "    'PM2.5': 'mean',        # Daily mean for PM2.5\n",
    "    'RAIN': 'sum',          # Total rainfall for the day\n",
    "    'TEMP': ['min', 'max'], # Min and Max for temperature\n",
    "    'WSP': 'max',           # Max wind speed for the day\n",
    "    'SD1': 'mean',          # Mean wind direction 1\n",
    "    'WDR': 'mean',          # Mean wind direction (special handling can be added)\n",
    "}\n",
    "\n",
    "df_wide_filled = df_wide.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "\n",
    "# Now resample the data into daily data based on the rules above\n",
    "daily_aggregated_mean = df_wide.resample('D').agg(aggregation_rules_mean)\n",
    "\n",
    "# Flatten the MultiIndex columns if needed\n",
    "daily_aggregated_mean.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in daily_aggregated_mean.columns]\n",
    "\n",
    "daily_aggregated_mean.interpolate(method='linear', inplace=True)\n",
    "\n",
    "# For columns that require rolling averages (if needed, change window size accordingly)\n",
    "# For example, for CO, we might want a 24-hour rolling average\n",
    "#daily_aggregated['CO_rolling_avg'] = df['CO'].resample('D').mean().rolling(window=24).mean()\n",
    "\n",
    "# Display the daily aggregated results\n",
    "#import ace_tools as tools; tools.display_dataframe_to_user(name=\"Daily Aggregated Data\", dataframe=daily_aggregated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa9bed33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/br/kn0p5yrn6d771z_m2v7qll780000gp/T/ipykernel_73596/1619163164.py:20: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the count of NaN values by time (i.e., how many NaNs per day)\n",
    "nan_by_time = daily_aggregated_mean.isna().sum(axis=1)\n",
    "\n",
    "# Plot the NaN counts over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(nan_by_time, color='red', marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of NaN values')\n",
    "plt.title('Number of NaN Values Over Time in daily_aggregated_mean DataFrame')\n",
    "\n",
    "# Rotating x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7d534af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3493 entries, 2015-04-01 to 2024-10-22\n",
      "Freq: D\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   CO_mean     3493 non-null   float64\n",
      " 1   HUMID_mean  3493 non-null   float64\n",
      " 2   NEPH_mean   3493 non-null   float64\n",
      " 3   NO_mean     3493 non-null   float64\n",
      " 4   NO2_mean    3493 non-null   float64\n",
      " 5   OZONE_mean  3493 non-null   float64\n",
      " 6   SO2_mean    3493 non-null   float64\n",
      " 7   PM10_mean   3493 non-null   float64\n",
      " 8   PM2.5_mean  3493 non-null   float64\n",
      " 9   RAIN_sum    3493 non-null   float64\n",
      " 10  TEMP_min    3493 non-null   float64\n",
      " 11  TEMP_max    3493 non-null   float64\n",
      " 12  WSP_max     3493 non-null   float64\n",
      " 13  SD1_mean    3493 non-null   float64\n",
      " 14  WDR_mean    3493 non-null   float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 436.6 KB\n"
     ]
    }
   ],
   "source": [
    "daily_aggregated_mean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d82d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_rules_max = {\n",
    "    'CO': 'max',           # Daily max for CO\n",
    "    'HUMID': 'max',        # Daily max for Humidity\n",
    "    'NEPH': 'max',         # Daily max for NEPH\n",
    "    'NO': 'max',           # Daily max for NO\n",
    "    'NO2': 'max',          # Daily max for NO2\n",
    "    'OZONE': 'max',        # Daily max for Ozone\n",
    "    'SO2': 'max',          # Daily max for SO2\n",
    "    'PM10': 'max',         # Daily max for PM10\n",
    "    'PM2.5': 'max',        # Daily max for PM2.5\n",
    "    'RAIN': 'sum',          # Total rainfall for the day\n",
    "    'TEMP': ['min', 'max'], # Min and Max for temperature\n",
    "    'WSP': 'max',           # Max wind speed for the day\n",
    "    'SD1': 'mean',          # Mean wind direction 1\n",
    "    'WDR': 'mean',          # Mean wind direction (special handling can be added)\n",
    "}\n",
    "\n",
    "# Resample the data into daily data based on the rules above\n",
    "daily_aggregated_max = df_wide.resample('D').agg(aggregation_rules_max)\n",
    "\n",
    "# Flatten the MultiIndex columns resulting from min/max aggregations\n",
    "daily_aggregated_max.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in daily_aggregated_max.columns]\n",
    "daily_aggregated_mean.interpolate(method='linear', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72bf1b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO_max</th>\n",
       "      <th>HUMID_max</th>\n",
       "      <th>NEPH_max</th>\n",
       "      <th>NO_max</th>\n",
       "      <th>NO2_max</th>\n",
       "      <th>OZONE_max</th>\n",
       "      <th>SO2_max</th>\n",
       "      <th>PM10_max</th>\n",
       "      <th>PM2.5_max</th>\n",
       "      <th>RAIN_sum</th>\n",
       "      <th>TEMP_min</th>\n",
       "      <th>TEMP_max</th>\n",
       "      <th>WSP_max</th>\n",
       "      <th>SD1_mean</th>\n",
       "      <th>WDR_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-04-01</th>\n",
       "      <td>0.754289</td>\n",
       "      <td>97.537</td>\n",
       "      <td>0.899</td>\n",
       "      <td>6.026604</td>\n",
       "      <td>2.222698</td>\n",
       "      <td>2.652025</td>\n",
       "      <td>0.314923</td>\n",
       "      <td>22.869</td>\n",
       "      <td>9.678</td>\n",
       "      <td>9.2</td>\n",
       "      <td>17.231</td>\n",
       "      <td>24.246</td>\n",
       "      <td>3.542</td>\n",
       "      <td>45.571000</td>\n",
       "      <td>151.538087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-02</th>\n",
       "      <td>0.551271</td>\n",
       "      <td>91.118</td>\n",
       "      <td>0.365</td>\n",
       "      <td>4.302611</td>\n",
       "      <td>3.694051</td>\n",
       "      <td>3.475725</td>\n",
       "      <td>1.668084</td>\n",
       "      <td>43.421</td>\n",
       "      <td>12.787</td>\n",
       "      <td>9.6</td>\n",
       "      <td>17.933</td>\n",
       "      <td>28.129</td>\n",
       "      <td>4.109</td>\n",
       "      <td>37.699458</td>\n",
       "      <td>207.560083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-03</th>\n",
       "      <td>0.241453</td>\n",
       "      <td>96.332</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.093866</td>\n",
       "      <td>0.910417</td>\n",
       "      <td>2.544125</td>\n",
       "      <td>0.290586</td>\n",
       "      <td>29.974</td>\n",
       "      <td>12.809</td>\n",
       "      <td>9.6</td>\n",
       "      <td>17.491</td>\n",
       "      <td>20.109</td>\n",
       "      <td>4.784</td>\n",
       "      <td>31.234500</td>\n",
       "      <td>185.386208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-04</th>\n",
       "      <td>0.266662</td>\n",
       "      <td>96.292</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.015641</td>\n",
       "      <td>1.143133</td>\n",
       "      <td>2.369700</td>\n",
       "      <td>0.031020</td>\n",
       "      <td>15.113</td>\n",
       "      <td>14.542</td>\n",
       "      <td>9.6</td>\n",
       "      <td>15.401</td>\n",
       "      <td>18.951</td>\n",
       "      <td>3.493</td>\n",
       "      <td>40.681625</td>\n",
       "      <td>155.968417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-05</th>\n",
       "      <td>0.380490</td>\n",
       "      <td>97.052</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.353037</td>\n",
       "      <td>1.911808</td>\n",
       "      <td>3.240400</td>\n",
       "      <td>0.271021</td>\n",
       "      <td>20.258</td>\n",
       "      <td>7.211</td>\n",
       "      <td>9.6</td>\n",
       "      <td>15.190</td>\n",
       "      <td>23.641</td>\n",
       "      <td>2.606</td>\n",
       "      <td>66.519583</td>\n",
       "      <td>214.499625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CO_max  HUMID_max  NEPH_max    NO_max   NO2_max  OZONE_max  \\\n",
       "datetime                                                                   \n",
       "2015-04-01  0.754289     97.537     0.899  6.026604  2.222698   2.652025   \n",
       "2015-04-02  0.551271     91.118     0.365  4.302611  3.694051   3.475725   \n",
       "2015-04-03  0.241453     96.332     0.495  0.093866  0.910417   2.544125   \n",
       "2015-04-04  0.266662     96.292     0.248  0.015641  1.143133   2.369700   \n",
       "2015-04-05  0.380490     97.052     0.237  0.353037  1.911808   3.240400   \n",
       "\n",
       "             SO2_max  PM10_max  PM2.5_max  RAIN_sum  TEMP_min  TEMP_max  \\\n",
       "datetime                                                                  \n",
       "2015-04-01  0.314923    22.869      9.678       9.2    17.231    24.246   \n",
       "2015-04-02  1.668084    43.421     12.787       9.6    17.933    28.129   \n",
       "2015-04-03  0.290586    29.974     12.809       9.6    17.491    20.109   \n",
       "2015-04-04  0.031020    15.113     14.542       9.6    15.401    18.951   \n",
       "2015-04-05  0.271021    20.258      7.211       9.6    15.190    23.641   \n",
       "\n",
       "            WSP_max   SD1_mean    WDR_mean  \n",
       "datetime                                    \n",
       "2015-04-01    3.542  45.571000  151.538087  \n",
       "2015-04-02    4.109  37.699458  207.560083  \n",
       "2015-04-03    4.784  31.234500  185.386208  \n",
       "2015-04-04    3.493  40.681625  155.968417  \n",
       "2015-04-05    2.606  66.519583  214.499625  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_aggregated_max.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb9c92b",
   "metadata": {},
   "source": [
    "# Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7db729d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/br/kn0p5yrn6d771z_m2v7qll780000gp/T/ipykernel_73596/451319404.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean.loc[:, 'datetime'] = pd.to_datetime(df_clean['date']) + pd.to_timedelta(df_clean['hour'], unit='h')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('traffic_victoria_road.csv')\n",
    "\n",
    "# Melt the DataFrame to convert the hour columns into rows\n",
    "df_melted = pd.melt(df, \n",
    "                    id_vars=['year', 'date', 'cardinal_direction_seq', 'classification_seq', 'public_holiday', 'school_holiday'],\n",
    "                    value_vars=[f'hour_{str(i).zfill(2)}' for i in range(24)],\n",
    "                    var_name='hour', \n",
    "                    value_name='traffic_count')\n",
    "\n",
    "# Clean up the 'hour' column (convert 'hour_00' to '00', 'hour_01' to '01', etc.)\n",
    "df_melted['hour'] = df_melted['hour'].str.replace('hour_', '').astype(int)\n",
    "\n",
    "# Pivot the DataFrame to separate 'Heavy Vehicles' and 'Light Vehicles' into their own columns\n",
    "df_pivoted = df_melted.pivot_table(index=['year', 'date', 'hour', 'public_holiday', 'school_holiday'],\n",
    "                                   columns='classification_seq', \n",
    "                                   values='traffic_count').reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "df_pivoted.columns.name = None  # Remove the pivot table's automatic column grouping name\n",
    "df_pivoted.rename(columns={'Heavy Vehicles': 'heavy_vehicle', 'Light Vehicles': 'light_vehicle'}, inplace=True)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_clean = df_pivoted.dropna()\n",
    "\n",
    "# Combine 'date' and 'hour' columns into a single 'datetime' column\n",
    "df_clean.loc[:, 'datetime'] = pd.to_datetime(df_clean['date']) + pd.to_timedelta(df_clean['hour'], unit='h')\n",
    "\n",
    "# Set 'datetime' as the index\n",
    "df_clean = df_clean.set_index('datetime')\n",
    "\n",
    "# Resample the data to daily frequency\n",
    "daily_traffic_data = df_clean.resample('D').agg({\n",
    "    'public_holiday': 'max',  # Taking the maximum value for the day\n",
    "    'school_holiday': 'max',  # Taking the maximum value for the day\n",
    "    'heavy_vehicle': 'sum',   # Summing heavy vehicle counts\n",
    "    'light_vehicle': 'sum'    # Summing light vehicle counts\n",
    "})\n",
    "\n",
    "\n",
    "# Create a list of school term date ranges for 2020 to 2025\n",
    "school_term_dates = [\n",
    "    # 2020 Term dates (Eastern and Western division)\n",
    "    ('2020-01-28', '2020-04-09'),  # Term 1 Eastern\n",
    "    ('2020-02-04', '2020-04-09'),  # Term 1 Western\n",
    "    ('2020-04-27', '2020-07-03'),  # Term 2\n",
    "    ('2020-07-20', '2020-09-25'),  # Term 3\n",
    "    ('2020-10-12', '2020-12-18'),  # Term 4\n",
    "    # 2021 Term dates\n",
    "    ('2021-01-27', '2021-04-01'),  # Term 1 Eastern\n",
    "    ('2021-02-03', '2021-04-01'),  # Term 1 Western\n",
    "    ('2021-04-19', '2021-06-25'),  # Term 2\n",
    "    ('2021-07-12', '2021-09-17'),  # Term 3\n",
    "    ('2021-10-05', '2021-12-17'),  # Term 4\n",
    "    # 2022 Term dates\n",
    "    ('2022-01-28', '2022-04-08'),  # Term 1 Eastern\n",
    "    ('2022-02-04', '2022-04-08'),  # Term 1 Western\n",
    "    ('2022-04-26', '2022-07-01'),  # Term 2\n",
    "    ('2022-07-18', '2022-09-23'),  # Term 3\n",
    "    ('2022-10-10', '2022-12-20'),  # Term 4\n",
    "    # 2023 Term dates\n",
    "    ('2023-01-27', '2023-04-06'),  # Term 1 Eastern\n",
    "    ('2023-02-03', '2023-04-06'),  # Term 1 Western\n",
    "    ('2023-04-24', '2023-06-30'),  # Term 2\n",
    "    ('2023-07-17', '2023-09-22'),  # Term 3\n",
    "    ('2023-10-09', '2023-12-19'),  # Term 4\n",
    "    # 2024 Term dates\n",
    "    ('2024-02-01', '2024-04-12'),  # Term 1 Eastern\n",
    "    ('2024-02-08', '2024-04-12'),  # Term 1 Western\n",
    "    ('2024-04-30', '2024-07-05'),  # Term 2\n",
    "    ('2024-07-23', '2024-09-27'),  # Term 3\n",
    "    ('2024-10-14', '2024-12-18'),  # Term 4\n",
    "    # 2025 Term dates\n",
    "    ('2025-02-04', '2025-04-11'),  # Term 1 Eastern\n",
    "    ('2025-02-11', '2025-04-11'),  # Term 1 Western\n",
    "    ('2025-04-30', '2025-07-04'),  # Term 2\n",
    "    ('2025-07-22', '2025-09-26'),  # Term 3\n",
    "    ('2025-10-13', '2025-12-19')   # Term 4\n",
    "]\n",
    "\n",
    "# Create a DataFrame for school term dates with 0 as school days\n",
    "df_school_term = pd.DataFrame({\n",
    "    'Start': pd.to_datetime([start for start, end in school_term_dates]),\n",
    "    'End': pd.to_datetime([end for start, end in school_term_dates]),\n",
    "    'school_holiday': 0  # School days are 0\n",
    "})\n",
    "\n",
    "# Create a date range DataFrame from 2020 to 2025\n",
    "date_range = pd.date_range(start='2020-01-01', end='2025-12-31', freq='D')\n",
    "df_dates = pd.DataFrame(date_range, columns=['datetime'])\n",
    "df_dates['school_holiday'] = 1  # Default to 1 (holidays)\n",
    "\n",
    "# Mark the term dates (non-holidays) as 0\n",
    "for _, row in df_school_term.iterrows():\n",
    "    df_dates.loc[(df_dates['datetime'] >= row['Start']) & (df_dates['datetime'] <= row['End']), 'school_holiday'] = 0\n",
    "\n",
    "# Data for public holidays from 2020 to 2025\n",
    "public_holidays = {\n",
    "    'holiday': [\n",
    "        \"New Year's Day\", \"Australia Day\", \"Good Friday\", \"Easter Saturday\", \"Easter Sunday\", \n",
    "        \"Easter Monday\", \"Anzac Day\", \"King's Birthday\", \"Labour Day\", \"Christmas Day\", \"Boxing Day\"\n",
    "    ],\n",
    "    '2020': [\n",
    "        '2020-01-01', '2020-01-27', '2020-04-10', '2020-04-11', '2020-04-12', \n",
    "        '2020-04-13', '2020-04-25', '2020-06-08', '2020-10-05', '2020-12-25', '2020-12-26'\n",
    "    ],\n",
    "    '2021': [\n",
    "        '2021-01-01', '2021-01-26', '2021-04-02', '2021-04-03', '2021-04-04', \n",
    "        '2021-04-05', '2021-04-25', '2021-06-14', '2021-10-04', '2021-12-25', '2021-12-26'\n",
    "    ],\n",
    "    '2022': [\n",
    "        '2022-01-01', '2022-01-26', '2022-04-15', '2022-04-16', '2022-04-17', \n",
    "        '2022-04-18', '2022-04-25', '2022-06-13', '2022-10-03', '2022-12-25', '2022-12-26'\n",
    "    ],\n",
    "    '2023': [\n",
    "        '2023-01-01', '2023-01-26', '2023-04-07', '2023-04-08', '2023-04-09', \n",
    "        '2023-04-10', '2023-04-25', '2023-06-12', '2023-10-02', '2023-12-25', '2023-12-26'\n",
    "    ],\n",
    "    '2024': [\n",
    "        '2024-01-01', '2024-01-26', '2024-03-29', '2024-03-30', '2024-03-31', \n",
    "        '2024-04-01', '2024-04-25', '2024-06-10', '2024-10-07', '2024-12-25', '2024-12-26'\n",
    "    ],\n",
    "    '2025': [\n",
    "        '2025-01-01', '2025-01-27', '2025-04-18', '2025-04-19', '2025-04-20', \n",
    "        '2025-04-21', '2025-04-25', '2025-06-09', '2025-10-06', '2025-12-25', '2025-12-26'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert public holiday data to a DataFrame\n",
    "df_holidays = pd.DataFrame(public_holidays)\n",
    "df_holidays_melted = df_holidays.melt(id_vars=['holiday'], var_name='Year', value_name='Date')\n",
    "df_holidays_melted = df_holidays_melted.dropna()\n",
    "df_holidays_melted['Date'] = pd.to_datetime(df_holidays_melted['Date'])\n",
    "df_holidays_melted['public_holiday'] = 1\n",
    "\n",
    "# Merge public holidays into the date range DataFrame\n",
    "df_final = pd.merge(df_dates, df_holidays_melted[['Date', 'public_holiday']], left_on='datetime', right_on='Date', how='left')\n",
    "df_final['public_holiday'] = df_final['public_holiday'].fillna(0).astype(int)\n",
    "\n",
    "# Drop unnecessary 'Date' column\n",
    "df_holiday = df_final.drop(columns=['Date'])\n",
    "\n",
    "\n",
    "# Get the first date in df_holiday\n",
    "first_date = df_holiday.index.min()\n",
    "\n",
    "df_holiday.set_index('datetime', inplace=True)\n",
    "#daily_traffic_data.set_index('datetime', inplace=True)\n",
    "\n",
    "\n",
    "# Combine both DataFrames to include all rows from df_holiday that are not present in daily_traffic_data\n",
    "# This will ensure that missing dates are added\n",
    "daily_traffic_data = daily_traffic_data.combine_first(df_holiday)\n",
    "\n",
    "# Update the 'school_holiday' and 'public_holiday' columns with values from df_holiday\n",
    "daily_traffic_data.update(df_holiday[['school_holiday', 'public_holiday']])\n",
    "\n",
    "\n",
    "# Using 'outer' join to ensure we keep all dates across the three DataFrames\n",
    "combined_data = pd.concat([daily_aggregated_mean, daily_traffic_data], axis=1, join='outer')\n",
    "\n",
    "# Drop the first row of the DataFrame\n",
    "combined_data = combined_data.iloc[1:]\n",
    "\n",
    "# Find the last entry (non-NaN) for 'heavy_vehicle'\n",
    "last_entry_date = combined_data['heavy_vehicle'].last_valid_index()\n",
    "\n",
    "# Forward fill NaN values for all columns between the second row and the last valid entry for 'heavy_vehicle'\n",
    "combined_data.loc[:last_entry_date] = combined_data.loc[:last_entry_date].fillna(method='ffill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cfadf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 'outer' join to ensure we keep all dates across the three DataFrames\n",
    "combined_data = pd.concat([daily_aggregated_mean, daily_traffic_data], axis=1, join='outer')\n",
    "\n",
    "# Drop the first row of the DataFrame\n",
    "combined_data = combined_data.iloc[1:]\n",
    "\n",
    "# Find the last entry (non-NaN) for 'heavy_vehicle'\n",
    "last_entry_date = combined_data['heavy_vehicle'].last_valid_index()\n",
    "\n",
    "# Forward fill NaN values for all columns between the second row and the last valid entry for 'heavy_vehicle'\n",
    "combined_data.loc[:last_entry_date] = combined_data.loc[:last_entry_date].fillna(method='ffill')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9630394f",
   "metadata": {},
   "source": [
    "# Weather Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72b3e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftplib import FTP\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Connect to FTP and download the XML file\n",
    "ftp = FTP('ftp.bom.gov.au')\n",
    "ftp.login()\n",
    "ftp.cwd('/anon/gen/fwo/')\n",
    "with open('IDN11060.xml', 'wb') as file:\n",
    "    ftp.retrbinary('RETR IDN11060.xml', file.write)\n",
    "ftp.quit()\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse('IDN11060.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Prepare an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Loop through each 'area' element to get all forecast data\n",
    "for area in root.findall('.//area'):\n",
    "    location = area.attrib.get('description')\n",
    "    \n",
    "    # Loop through each forecast period in the location\n",
    "    for period in area.findall('.//forecast-period'):\n",
    "        start_time = period.attrib.get('start-time-local')\n",
    "        \n",
    "        # Initialize a dictionary to hold the data for this forecast period\n",
    "        forecast_data = {\n",
    "            'Location': location,\n",
    "            'Date': start_time\n",
    "        }\n",
    "        \n",
    "        # Loop through all 'element' tags\n",
    "        for element in period.findall('element'):\n",
    "            param_type = element.attrib.get('type')\n",
    "            value = element.text\n",
    "            units = element.attrib.get('units', '')\n",
    "            forecast_data[f'{param_type} ({units})'] = value\n",
    "        \n",
    "        # Loop through all 'text' tags\n",
    "        for text in period.findall('text'):\n",
    "            text_type = text.attrib.get('type')\n",
    "            text_value = text.text\n",
    "            forecast_data[text_type] = text_value\n",
    "        \n",
    "        # Append the forecast data to the list\n",
    "        data.append(forecast_data)\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df[['Location', 'Date', \n",
    "             'air_temperature_maximum (Celsius)', 'air_temperature_minimum (Celsius)', \n",
    "             'precipitation_range ()']].copy()\n",
    "\n",
    "# Renaming the columns to the desired format\n",
    "df.columns = ['Location', 'Date', 'Temp_Max', 'Temp_Min', 'Rain']\n",
    "\n",
    "def extract_rain_value(rain):\n",
    "    if pd.isnull(rain):\n",
    "        return 0  # If NaN, return 0\n",
    "    # Extract the larger number from strings like \"0 to 2 mm\"\n",
    "    rain_values = re.findall(r'\\d+', rain)\n",
    "    if rain_values:\n",
    "        return int(rain_values[-1])  # Return the largest number (last in the list)\n",
    "    return 0  # Default to 0 if no numbers are found\n",
    "\n",
    "# Apply the extraction function to the 'Rain' column\n",
    "df['Rain'] = df['Rain'].apply(extract_rain_value)\n",
    "\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Convert 'Temp_Max' and 'Temp_Min' columns to numeric, forcing errors to NaN if conversion fails\n",
    "df['Temp_Max'] = pd.to_numeric(df['Temp_Max'], errors='coerce')\n",
    "df['Temp_Min'] = pd.to_numeric(df['Temp_Min'], errors='coerce')\n",
    "\n",
    "# Calculating the difference between Temp_Max and Temp_Min for each row\n",
    "df['Temp_Diff'] = df['Temp_Max'] - df['Temp_Min']\n",
    "\n",
    "# Calculating the average difference between Temp_Max and Temp_Min (excluding NaN values)\n",
    "avg_temp_diff = df['Temp_Diff'].mean()\n",
    "\n",
    "# Filling the NaN values in Temp_Min by subtracting the average temperature difference from Temp_Max\n",
    "df['Temp_Min'].fillna(df['Temp_Max'] - avg_temp_diff, inplace=True)\n",
    "\n",
    "# Dropping the Temp_Diff column as it's no longer needed\n",
    "df.drop(columns=['Temp_Diff'], inplace=True)\n",
    "\n",
    "df_sydney = df[df['Location'] == 'Sydney'].copy()\n",
    "# Connect to FTP and download the XML file\n",
    "ftp = FTP('ftp.bom.gov.au')\n",
    "ftp.login()\n",
    "ftp.cwd('/anon/gen/fwo/')\n",
    "with open('IDN11050.xml', 'wb') as file:\n",
    "    ftp.retrbinary('RETR IDN11050.xml', file.write)\n",
    "ftp.quit()\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse('IDN11050.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Prepare an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Loop through each 'area' element to get all forecast data\n",
    "for area in root.findall('.//area'):\n",
    "    location = area.attrib.get('description')\n",
    "    \n",
    "    # Loop through each forecast period in the location\n",
    "    for period in area.findall('.//forecast-period'):\n",
    "        start_time = period.attrib.get('start-time-local')\n",
    "        \n",
    "        # Initialize a dictionary to hold the data for this forecast period\n",
    "        forecast_data = {\n",
    "            'Location': location,\n",
    "            'Date': start_time\n",
    "        }\n",
    "        \n",
    "        # Loop through all 'element' tags\n",
    "        for element in period.findall('element'):\n",
    "            param_type = element.attrib.get('type')\n",
    "            value = element.text\n",
    "            units = element.attrib.get('units', '')\n",
    "            forecast_data[f'{param_type} ({units})'] = value\n",
    "        \n",
    "        # Loop through all 'text' tags\n",
    "        for text in period.findall('text'):\n",
    "            text_type = text.attrib.get('type')\n",
    "            text_value = text.text\n",
    "            forecast_data[text_type] = text_value\n",
    "        \n",
    "        # Append the forecast data to the list\n",
    "        data.append(forecast_data)\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df_wind = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Mapping wind direction text to degrees\n",
    "wind_direction_degrees = {\n",
    "    'northerly': 0, 'north to northeasterly': 22.5, 'northeasterly': 45, 'east to northeasterly': 67.5,\n",
    "    'easterly': 90, 'east to southeasterly': 112.5, 'southeast': 135, 'south to southeast': 157.5,\n",
    "    'southerly': 180, 'south to southwesterly': 202.5, 'southwesterly': 225, 'west-southwesterly': 247.5,\n",
    "    'westerly': 270, 'west to northwesterly': 292.5, 'northwesterly': 315, 'north to northwesterly': 337.5\n",
    "}\n",
    "\n",
    "# Function to extract wind speed and direction from the 'Forecast' column\n",
    "def extract_wind_info(forecast):\n",
    "    if pd.isnull(forecast):\n",
    "        return None, None, None  # Handle None or NaN values\n",
    "    \n",
    "    \n",
    "    # Regular expression to handle both \"Winds ...\" and \"becoming ...\"\n",
    "    wind_info = re.search(r'(Winds|becoming)\\s([a-zA-Z\\s]+)\\s(\\d+)(?:\\sto\\s(\\d+))?\\skm/h', forecast)\n",
    "    \n",
    "    if wind_info:\n",
    "        wind_direction = wind_info.group(2).strip().lower()\n",
    "        wind_speed_min = int(wind_info.group(3))\n",
    "        wind_speed_max = int(wind_info.group(4)) if wind_info.group(4) else None\n",
    "        \n",
    "        # Convert the wind direction to degrees if it's in the mapping\n",
    "        for direction, degrees in wind_direction_degrees.items():\n",
    "            if direction in wind_direction:\n",
    "                wind_direction_degrees_value = degrees\n",
    "                break\n",
    "        else:\n",
    "            wind_direction_degrees_value = None  # Handle unknown direction\n",
    "        \n",
    "        return wind_direction_degrees_value, wind_speed_min, wind_speed_max\n",
    "    \n",
    "    return None, None, None\n",
    "\n",
    "# Apply the function to the 'Forecast' column and store the results in new columns\n",
    "df_wind['Wind Direction (Degrees)'], df_wind['Wind Speed Min'], df_wind['Wind Speed Max'] = zip(*df_wind['forecast'].apply(extract_wind_info))\n",
    "\n",
    "def kmh_to_ms(speed_kmh):\n",
    "    return round(speed_kmh * 0.27778, 2) if speed_kmh is not None else None\n",
    "\n",
    "# Apply the conversion after extracting the wind data\n",
    "df_wind['Wind Speed Min (m/s)'] = df_wind['Wind Speed Min'].apply(kmh_to_ms)\n",
    "df_wind['Wind Speed Max (m/s)'] = df_wind['Wind Speed Max'].apply(kmh_to_ms)\n",
    "df_wind['Date'] = pd.to_datetime(df_wind['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Display the extracted wind information\n",
    "df_wind=df_wind[['Location',\n",
    "                 'Date','Wind Direction (Degrees)', \n",
    "                 'Wind Speed Min (m/s)', \n",
    "                 'Wind Speed Max (m/s)',\n",
    "                 'forecast']]\n",
    "\n",
    "df_wind_sydney = df_wind[df_wind['Location'] == 'Sydney'][['Date', \n",
    "                                                           'Wind Direction (Degrees)', \n",
    "                                                           'Wind Speed Min (m/s)', \n",
    "                                                           'Wind Speed Max (m/s)',\n",
    "                                                           'forecast']].copy()\n",
    "\n",
    "df_forecast_sydney = pd.merge(df_sydney, df_wind_sydney, on='Date', how='inner')\n",
    "\n",
    "df_forecast_sydney = df_forecast_sydney.drop(columns=['Location'])  # Drop the \"Location\" column\n",
    "df_forecast_sydney['Date'] = pd.to_datetime(df_forecast_sydney['Date'])  # Convert 'Date' column to datetime\n",
    "df_forecast_sydney = df_forecast_sydney.set_index('Date')  # Set 'Date' as the index\n",
    "\n",
    "\n",
    "df_forecast_sydney.rename(columns={\n",
    "    'Rain': 'RAIN_sum',\n",
    "    'Wind Direction (Degrees)': 'WDR_mean',\n",
    "    'Wind Speed Max (m/s)': 'WSP_max',\n",
    "    'Temp_Max': 'TEMP_max',\n",
    "    'Temp_Min': 'TEMP_min',\n",
    "    'forecast': 'forecast'\n",
    "}, inplace=True)\n",
    "\n",
    "df_7forecast_sydney = df_forecast_sydney[['TEMP_max', \n",
    "                                          'TEMP_min', \n",
    "                                          'RAIN_sum', \n",
    "                                          'WSP_max', \n",
    "                                          'WDR_mean',\n",
    "                                         'forecast']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a40e105d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMP_max</th>\n",
       "      <th>TEMP_min</th>\n",
       "      <th>RAIN_sum</th>\n",
       "      <th>WSP_max</th>\n",
       "      <th>WDR_mean</th>\n",
       "      <th>forecast</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clear. Light winds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-23</th>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mostly sunny morning. The chance of fog in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-24</th>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5.56</td>\n",
       "      <td>202.5</td>\n",
       "      <td>Partly cloudy. High chance of showers, most li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-25</th>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.56</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Partly cloudy. Medium chance of showers. Winds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-26</th>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.56</td>\n",
       "      <td>202.5</td>\n",
       "      <td>Partly cloudy. Slight chance of a shower in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TEMP_max  TEMP_min  RAIN_sum  WSP_max  WDR_mean  \\\n",
       "Date                                                          \n",
       "2024-10-22       NaN       NaN         0      NaN       NaN   \n",
       "2024-10-23      27.0      14.0         0      NaN       NaN   \n",
       "2024-10-24      23.0      17.0         9     5.56     202.5   \n",
       "2024-10-25      21.0      13.0         2     5.56     180.0   \n",
       "2024-10-26      20.0      14.0         1     5.56     202.5   \n",
       "\n",
       "                                                     forecast  \n",
       "Date                                                           \n",
       "2024-10-22                                Clear. Light winds.  \n",
       "2024-10-23  Mostly sunny morning. The chance of fog in the...  \n",
       "2024-10-24  Partly cloudy. High chance of showers, most li...  \n",
       "2024-10-25  Partly cloudy. Medium chance of showers. Winds...  \n",
       "2024-10-26  Partly cloudy. Slight chance of a shower in th...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_7forecast_sydney.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0611a5",
   "metadata": {},
   "source": [
    "# Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f08fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both DataFrames have their indices in datetime format\n",
    "combined_data.index = pd.to_datetime(combined_data.index)\n",
    "df_7forecast_sydney.index = pd.to_datetime(df_7forecast_sydney.index)\n",
    "\n",
    "# Remove any overlapping dates between the indices of combined_data and df_7forecast_sydney\n",
    "combined_data = combined_data[~combined_data.index.isin(df_7forecast_sydney.index)]\n",
    "\n",
    "# Combine df_7forecast_sydney into combined_data, updating existing columns\n",
    "combined_data = pd.concat([combined_data, df_7forecast_sydney], axis=0, join='outer')\n",
    "\n",
    "# Sort by index (date)\n",
    "combined_data = combined_data.sort_index()\n",
    "\n",
    "# Drop the first row of the DataFrame if needed\n",
    "combined_data = combined_data.iloc[1:]\n",
    "\n",
    "# Find the last entry (non-NaN) for 'heavy_vehicle'\n",
    "last_entry_date = combined_data['heavy_vehicle'].last_valid_index()\n",
    "\n",
    "# Forward fill NaN values for all columns between the second row and the last valid entry for 'heavy_vehicle'\n",
    "combined_data.loc[:last_entry_date] = combined_data.loc[:last_entry_date].fillna(method='ffill')\n",
    "\n",
    "# Display the final combined DataFrame to check the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c493e248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CO_mean            0.192535\n",
       "HUMID_mean        75.038333\n",
       "NEPH_mean          0.204792\n",
       "NO_mean           -0.001461\n",
       "NO2_mean           0.486783\n",
       "OZONE_mean         2.190367\n",
       "SO2_mean            0.01448\n",
       "PM10_mean         15.299292\n",
       "PM2.5_mean         4.935708\n",
       "RAIN_sum                7.6\n",
       "TEMP_min             13.933\n",
       "TEMP_max             17.209\n",
       "WSP_max               3.727\n",
       "SD1_mean          40.247292\n",
       "WDR_mean            183.219\n",
       "heavy_vehicle           NaN\n",
       "light_vehicle           NaN\n",
       "public_holiday          0.0\n",
       "school_holiday          0.0\n",
       "forecast                NaN\n",
       "Name: 2024-10-15 00:00:00, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.loc['2024-10-15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3410be16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/br/kn0p5yrn6d771z_m2v7qll780000gp/T/ipykernel_73596/1223993972.py:13: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_columns(df, columns):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            plt.plot(df.index, df[column], label=column)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Time Series Data')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage: Plot multiple columns\n",
    "plot_columns(combined_data, ['CO_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b56a8ca",
   "metadata": {},
   "source": [
    "# Traffic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc08946b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "2024-10-22 18:53:20.075025: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.0843 - val_loss: 0.0400\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.0517 - val_loss: 0.0378\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.0504 - val_loss: 0.0353\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.0482 - val_loss: 0.0336\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.0437 - val_loss: 0.0365\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 2s 27ms/step - loss: 0.0409 - val_loss: 0.0299\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.0381 - val_loss: 0.0286\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.0366 - val_loss: 0.0278\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - 2s 28ms/step - loss: 0.0358 - val_loss: 0.0263\n",
      "Epoch 10/10\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.0353 - val_loss: 0.0269\n",
      "22/22 [==============================] - 0s 10ms/step\n",
      "19/22 [========================>.....] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 10ms/step\n",
      "RMSE (Heavy Vehicle): 515.9587848013232\n",
      "RMSE (Light Vehicle): 5739.531788536851\n",
      "MAE (Heavy Vehicle): 332.2483031599182\n",
      "MAE (Light Vehicle): 3728.2673974394274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/br/kn0p5yrn6d771z_m2v7qll780000gp/T/ipykernel_73596/4231650166.py:95: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/var/folders/br/kn0p5yrn6d771z_m2v7qll780000gp/T/ipykernel_73596/4231650166.py:103: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/var/folders/br/kn0p5yrn6d771z_m2v7qll780000gp/T/ipykernel_73596/4231650166.py:110: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "#  Prepare the data\n",
    "# Select the features to include in the model (in addition to 'heavy_vehicle' and 'light_vehicle')\n",
    "features = ['heavy_vehicle', 'light_vehicle','RAIN_sum']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(combined_data[features])  # Scale selected columns\n",
    "\n",
    "# Create a new DataFrame with the scaled data and the same index\n",
    "combined_data_scaled = pd.DataFrame(scaled_data, columns=features, index=combined_data.index)\n",
    "\n",
    "#  Handle missing values\n",
    "# Find the first missing value in either 'heavy_vehicle' or 'light_vehicle'\n",
    "first_missing_index = combined_data[['heavy_vehicle', 'light_vehicle']].isnull().idxmax().max()\n",
    "\n",
    "# Convert the first_missing_index to its integer location\n",
    "first_missing_loc = combined_data.index.get_loc(first_missing_index)\n",
    "\n",
    "# Filter data up to the first missing value\n",
    "combined_data_filtered = combined_data_scaled.iloc[:first_missing_loc] \n",
    "\n",
    "# Create sequences (LSTM expects a 3D input: [samples, timesteps, features])\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        X.append(data[i-seq_length:i])  # Input sequence\n",
    "        y.append(data[i, :2])           # Target for heavy_vehicle (0) and light_vehicle (1)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define the sequence length and reshape the data for LSTM\n",
    "sequence_length = 7  # 7-day sequences\n",
    "data = combined_data_filtered.values  # Use scaled and filtered data with multiple features\n",
    "X, y = create_sequences(data, sequence_length)\n",
    "\n",
    "# Split the data into training and testing data\n",
    "split_index = int(len(combined_data_filtered) * 0.8)  # Use 80% for training, 20% for testing\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Define the LSTM model (with multiple input features and two outputs for heavy_vehicle and light_vehicle)\n",
    "model = Sequential()\n",
    "# Adjust input shape to account for the number of features (len(features))\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(sequence_length, len(features))))  # Use all selected features\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(2))  # Predict two values at a time (for heavy_vehicle and light_vehicle)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the LSTM model to predict both heavy_vehicle and light_vehicle\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Apply MinMaxScaler only for heavy_vehicle and light_vehicle\n",
    "scaler_vehicle = MinMaxScaler()\n",
    "scaler_vehicle.fit(combined_data[['heavy_vehicle', 'light_vehicle']])  # Fit scaler on only these two columns\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions and actual values (for comparison)\n",
    "y_pred_inverse = scaler_vehicle.inverse_transform(y_pred)\n",
    "y_test_inverse = scaler_vehicle.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE and MAE for both heavy_vehicle and light_vehicle (same as before)\n",
    "rmse_heavy_vehicle = np.sqrt(mean_squared_error(y_test_inverse[:, 0], y_pred_inverse[:, 0]))\n",
    "rmse_light_vehicle = np.sqrt(mean_squared_error(y_test_inverse[:, 1], y_pred_inverse[:, 1]))\n",
    "\n",
    "mae_heavy_vehicle = mean_absolute_error(y_test_inverse[:, 0], y_pred_inverse[:, 0])\n",
    "mae_light_vehicle = mean_absolute_error(y_test_inverse[:, 1], y_pred_inverse[:, 1])\n",
    "\n",
    "print(f\"RMSE (Heavy Vehicle): {rmse_heavy_vehicle}\")\n",
    "print(f\"RMSE (Light Vehicle): {rmse_light_vehicle}\")\n",
    "\n",
    "print(f\"MAE (Heavy Vehicle): {mae_heavy_vehicle}\")\n",
    "print(f\"MAE (Light Vehicle): {mae_light_vehicle}\")\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot actual vs predicted values for heavy_vehicle and light_vehicle\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test_inverse[:, 0], label='Actual Heavy Vehicle')\n",
    "plt.plot(y_pred_inverse[:, 0], label='Predicted Heavy Vehicle', linestyle='--')\n",
    "plt.title('Actual vs Predicted Heavy Vehicle')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test_inverse[:, 1], label='Actual Light Vehicle')\n",
    "plt.plot(y_pred_inverse[:, 1], label='Predicted Light Vehicle', linestyle='--')\n",
    "plt.title('Actual vs Predicted Light Vehicle')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c3179",
   "metadata": {},
   "source": [
    "# Traffic Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed75e95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "             CO_mean  HUMID_mean  NEPH_mean   NO_mean  NO2_mean  OZONE_mean  \\\n",
      "2024-09-01  0.137270   31.843417   0.058875 -0.001673  0.256140    3.054250   \n",
      "2024-09-02  0.135443   29.808250   0.079292 -0.028163  0.086860    3.188738   \n",
      "2024-09-03  0.151750   42.383500   0.083542  0.063050  0.559288    2.637529   \n",
      "2024-09-04  0.275515   61.051917   0.279458  0.861777  1.337082    1.789696   \n",
      "2024-09-05  0.267276   48.832208   0.256958  0.768037  1.220985    2.048054   \n",
      "...              ...         ...        ...       ...       ...         ...   \n",
      "2025-12-27       NaN         NaN        NaN       NaN       NaN         NaN   \n",
      "2025-12-28       NaN         NaN        NaN       NaN       NaN         NaN   \n",
      "2025-12-29       NaN         NaN        NaN       NaN       NaN         NaN   \n",
      "2025-12-30       NaN         NaN        NaN       NaN       NaN         NaN   \n",
      "2025-12-31       NaN         NaN        NaN       NaN       NaN         NaN   \n",
      "\n",
      "            SO2_mean  PM10_mean  PM2.5_mean  RAIN_sum  TEMP_min  TEMP_max  \\\n",
      "2024-09-01  0.040029  10.438083    4.179958       0.0    13.100    26.888   \n",
      "2024-09-02  0.024711  20.109500    5.026625       0.0    13.954    24.786   \n",
      "2024-09-03  0.003157  14.314625    6.153500       0.0     9.792    16.710   \n",
      "2024-09-04  0.190881  23.162625   11.925792       0.0     7.778    20.559   \n",
      "2024-09-05  0.086084  23.843208   11.811500       0.0    10.551    26.910   \n",
      "...              ...        ...         ...       ...       ...       ...   \n",
      "2025-12-27       NaN        NaN         NaN       NaN       NaN       NaN   \n",
      "2025-12-28       NaN        NaN         NaN       NaN       NaN       NaN   \n",
      "2025-12-29       NaN        NaN         NaN       NaN       NaN       NaN   \n",
      "2025-12-30       NaN        NaN         NaN       NaN       NaN       NaN   \n",
      "2025-12-31       NaN        NaN         NaN       NaN       NaN       NaN   \n",
      "\n",
      "            WSP_max   SD1_mean    WDR_mean  heavy_vehicle  light_vehicle  \\\n",
      "2024-09-01    3.241  44.069750  282.295833    1029.416992   10403.224609   \n",
      "2024-09-02    3.946  58.665083  266.924875    1440.549683   12041.528320   \n",
      "2024-09-03    3.421  61.781833  160.624042    1447.343750   13334.653320   \n",
      "2024-09-04    4.187  26.990375  164.751917    1550.468872   15607.325195   \n",
      "2024-09-05    2.865  47.072583  280.677583    1590.617432   17923.541016   \n",
      "...             ...        ...         ...            ...            ...   \n",
      "2025-12-27      NaN        NaN         NaN            NaN            NaN   \n",
      "2025-12-28      NaN        NaN         NaN            NaN            NaN   \n",
      "2025-12-29      NaN        NaN         NaN            NaN            NaN   \n",
      "2025-12-30      NaN        NaN         NaN            NaN            NaN   \n",
      "2025-12-31      NaN        NaN         NaN            NaN            NaN   \n",
      "\n",
      "            public_holiday  school_holiday forecast  \n",
      "2024-09-01             0.0             0.0      NaN  \n",
      "2024-09-02             0.0             0.0      NaN  \n",
      "2024-09-03             0.0             0.0      NaN  \n",
      "2024-09-04             0.0             0.0      NaN  \n",
      "2024-09-05             0.0             0.0      NaN  \n",
      "...                    ...             ...      ...  \n",
      "2025-12-27             0.0             1.0      NaN  \n",
      "2025-12-28             0.0             1.0      NaN  \n",
      "2025-12-29             0.0             1.0      NaN  \n",
      "2025-12-30             0.0             1.0      NaN  \n",
      "2025-12-31             0.0             1.0      NaN  \n",
      "\n",
      "[487 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Prepare to make rolling predictions from the first missing value until 8 days from today\n",
    "today = pd.Timestamp.today()\n",
    "days_to_predict = (today - first_missing_index).days + 8  # From first missing value to 8 days from today\n",
    "\n",
    "# Step 2: Prepare the last valid sequence for prediction\n",
    "# Assume the model was trained on a sequence of 7 days and all features were used in training\n",
    "last_sequence = combined_data_scaled.iloc[first_missing_loc-sequence_length:first_missing_loc].values\n",
    "pred_input = np.array([last_sequence])\n",
    "\n",
    "# Step 3: Predict for all missing days and 8 days into the future (Rolling Forecast)\n",
    "predictions_future = []\n",
    "for _ in range(days_to_predict):\n",
    "    # Predict one step ahead\n",
    "    pred = model.predict(pred_input)\n",
    "    predictions_future.append(pred[0])  # Store the prediction for the current step\n",
    "    \n",
    "    # Update pred_input by appending the prediction and removing the first timestep\n",
    "    pred_input = np.append(pred_input[:, 1:, :], [[np.hstack([pred_input[0, -1, 2:], pred[0]])]], axis=1)\n",
    "\n",
    "# Step 4: Inverse transform the predictions ONLY for heavy_vehicle and light_vehicle\n",
    "# Assuming the scaler was originally fitted only on 'heavy_vehicle' and 'light_vehicle' columns\n",
    "predictions_future = np.array(predictions_future)\n",
    "\n",
    "# Perform the inverse transform only on the 2 columns (heavy_vehicle, light_vehicle)\n",
    "scaler_vehicle = MinMaxScaler()\n",
    "scaler_vehicle.fit(combined_data[['heavy_vehicle', 'light_vehicle']])  # Fit the scaler only on relevant columns\n",
    "predictions_future_scaled = scaler_vehicle.inverse_transform(predictions_future[:, :2])  # Inverse-transform only the 2 columns\n",
    "\n",
    "# Step 5: Create a DataFrame of the predicted values\n",
    "predicted_dates = pd.date_range(start=first_missing_index, periods=days_to_predict)\n",
    "predicted_values_df = pd.DataFrame(predictions_future_scaled, columns=['heavy_vehicle', 'light_vehicle'], index=predicted_dates)\n",
    "\n",
    "# Step 6: Update the original combined_data DataFrame with the predictions\n",
    "combined_data.update(predicted_values_df)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(combined_data.loc[first_missing_index:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "218f25bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/br/kn0p5yrn6d771z_m2v7qll780000gp/T/ipykernel_73596/3199428479.py:23: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Plot the actual and predicted values for heavy_vehicle and light_vehicle\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot for heavy_vehicle\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(combined_data.index, combined_data['heavy_vehicle'], label='Actual Heavy Vehicle', color='blue')\n",
    "plt.plot(predicted_values_df.index, predicted_values_df['heavy_vehicle'], label='Predicted Heavy Vehicle', color='red', linestyle='--')\n",
    "plt.title('Heavy Vehicle Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Heavy Vehicle Count')\n",
    "plt.legend()\n",
    "\n",
    "# Plot for light_vehicle\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(combined_data.index, combined_data['light_vehicle'], label='Actual Light Vehicle', color='blue')\n",
    "plt.plot(predicted_values_df.index, predicted_values_df['light_vehicle'], label='Predicted Light Vehicle', color='red', linestyle='--')\n",
    "plt.title('Light Vehicle Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Light Vehicle Count')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885595db",
   "metadata": {},
   "source": [
    "# Air Quality Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0693666a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 4/88 [>.............................] - ETA: 1s - loss: 0.0289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 2s 25ms/step - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 2s 26ms/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 0.0069 - val_loss: 0.0055\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 0.0068 - val_loss: 0.0055\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 2s 27ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 2s 26ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 2s 26ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 2s 28ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 2s 28ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 2s 26ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "22/22 [==============================] - 0s 12ms/step\n",
      "RMSE (CO_mean): 0.07683732150824699\n",
      "RMSE (NO2_mean): 0.4135195949390155\n",
      "RMSE (NO_mean): 0.526748150112218\n",
      "RMSE (OZONE_mean): 0.5724367853537059\n",
      "RMSE (PM10_mean): 5.890892157840213\n",
      "RMSE (PM2.5_mean): 3.531774773456708\n",
      "RMSE (SO2_mean): 0.10442390171158525\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Step 1: Prepare the data\n",
    "features = ['TEMP_min', 'TEMP_max', 'RAIN_sum', 'WDR_mean', 'WSP_max', 'heavy_vehicle', 'light_vehicle']\n",
    "target = ['CO_mean', 'NO2_mean', 'NO_mean', 'OZONE_mean', 'PM10_mean', 'PM2.5_mean', 'SO2_mean']\n",
    "\n",
    "# Scale the features and target variables\n",
    "scaler_features = MinMaxScaler()\n",
    "scaled_features = scaler_features.fit_transform(combined_data[features])\n",
    "\n",
    "scaler_target = MinMaxScaler()\n",
    "scaled_target = scaler_target.fit_transform(combined_data[target])\n",
    "\n",
    "# Combine the scaled features and targets into a single DataFrame\n",
    "combined_data_scaled = pd.DataFrame(np.hstack([scaled_features, scaled_target]), \n",
    "                                    columns=features + target, \n",
    "                                    index=combined_data.index)\n",
    "\n",
    "# Handle missing values\n",
    "first_missing_index = combined_data[target].isnull().idxmax().max()\n",
    "first_missing_loc = combined_data.index.get_loc(first_missing_index)\n",
    "\n",
    "# Filter data up to the first missing value\n",
    "combined_data_filtered = combined_data_scaled.iloc[:first_missing_loc]\n",
    "\n",
    "# Create sequences (LSTM expects a 3D input: [samples, timesteps, features])\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        X.append(data[i-seq_length:i, :len(features)])  # Input sequence (features)\n",
    "        y.append(data[i, len(features):])              # Target sequence (CO, NO2, etc.)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define the sequence length (7-day sequences)\n",
    "sequence_length = 7\n",
    "data = combined_data_filtered.values\n",
    "X, y = create_sequences(data, sequence_length)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "split_index = int(len(combined_data_filtered) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Build and compile the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(sequence_length, len(features))))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(len(target)))  # Output layer for the 7 target variables\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the LSTM model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predicted and actual values for comparison\n",
    "y_pred_inverse = scaler_target.inverse_transform(y_pred)\n",
    "y_test_inverse = scaler_target.inverse_transform(y_test)\n",
    "\n",
    "# Calculate RMSE for each target variable\n",
    "for i, target_name in enumerate(target):\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_inverse[:, i], y_pred_inverse[:, i]))\n",
    "    print(f\"RMSE ({target_name}): {rmse}\")\n",
    "\n",
    "# Save the model for the prediction step\n",
    "model.save(\"lstm_air_quality_model.h5\")\n",
    "np.save(\"scaler_features.npy\", scaler_features)\n",
    "np.save(\"scaler_target.npy\", scaler_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d5b401",
   "metadata": {},
   "source": [
    "# Rewrite Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c892513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both DataFrames have their indices in datetime format\n",
    "combined_data.index = pd.to_datetime(combined_data.index)\n",
    "df_7forecast_sydney.index = pd.to_datetime(df_7forecast_sydney.index)\n",
    "\n",
    "# Overwrite only the rows in combined_data where the dates overlap with df_7forecast_sydney\n",
    "# This will keep all existing data in combined_data except for the overlapping dates, which will be replaced\n",
    "combined_data.update(df_7forecast_sydney)\n",
    "\n",
    "# Optionally, sort the DataFrame by the index to ensure the data is in chronological order\n",
    "combined_data = combined_data.sort_index()\n",
    "\n",
    "# Drop the first row of the DataFrame if needed\n",
    "combined_data = combined_data.iloc[1:]\n",
    "\n",
    "# Find the last valid entry for 'heavy_vehicle'\n",
    "last_entry_date = combined_data['heavy_vehicle'].last_valid_index()\n",
    "\n",
    "# Forward fill NaN values for all columns up to the last valid entry for 'heavy_vehicle'\n",
    "combined_data.loc[:last_entry_date] = combined_data.loc[:last_entry_date].fillna(method='ffill')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acd47a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CO_mean             0.219916\n",
       "HUMID_mean         68.715583\n",
       "NEPH_mean           0.275667\n",
       "NO_mean            -0.010445\n",
       "NO2_mean            0.059327\n",
       "OZONE_mean          2.696521\n",
       "SO2_mean           -0.015946\n",
       "PM10_mean             18.784\n",
       "PM2.5_mean          7.095042\n",
       "RAIN_sum                 0.0\n",
       "TEMP_min              17.259\n",
       "TEMP_max              19.897\n",
       "WSP_max                5.225\n",
       "SD1_mean           23.315792\n",
       "WDR_mean          187.805792\n",
       "heavy_vehicle     876.834229\n",
       "light_vehicle        15244.5\n",
       "public_holiday           0.0\n",
       "school_holiday           0.0\n",
       "forecast                 NaN\n",
       "Name: 2024-10-20 00:00:00, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.loc['2024-10-20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a4b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "417ef6aa",
   "metadata": {},
   "source": [
    "# Air Quality Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da8ac7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "             CO_mean  HUMID_mean  NEPH_mean   NO_mean  NO2_mean  OZONE_mean  \\\n",
      "2024-10-22  0.165748   64.559833   0.134583  0.230865  0.455354    1.728650   \n",
      "2024-10-23  0.187882   64.559833   0.134583  0.547301  0.668562    1.514649   \n",
      "2024-10-24  0.208911   64.559833   0.134583  0.815310  0.874443    1.370425   \n",
      "2024-10-25  0.225088   64.559833   0.134583  1.000517  1.017205    1.252399   \n",
      "2024-10-26  0.242674   64.559833   0.134583  1.047098  1.117258    1.296528   \n",
      "...              ...         ...        ...       ...       ...         ...   \n",
      "2025-12-27       NaN         NaN        NaN       NaN       NaN         NaN   \n",
      "2025-12-28       NaN         NaN        NaN       NaN       NaN         NaN   \n",
      "2025-12-29       NaN         NaN        NaN       NaN       NaN         NaN   \n",
      "2025-12-30       NaN         NaN        NaN       NaN       NaN         NaN   \n",
      "2025-12-31       NaN         NaN        NaN       NaN       NaN         NaN   \n",
      "\n",
      "            SO2_mean  PM10_mean  PM2.5_mean  RAIN_sum  TEMP_min  TEMP_max  \\\n",
      "2024-10-22  0.038801  12.688401    2.575596       0.0    15.838    19.424   \n",
      "2024-10-23  0.049858  11.142067    3.073559       0.0    14.000    27.000   \n",
      "2024-10-24  0.066353  11.072093    3.793838       9.0    17.000    23.000   \n",
      "2024-10-25  0.080411  11.480001    4.449006       2.0    13.000    21.000   \n",
      "2024-10-26  0.091702  12.157179    5.388426       1.0    14.000    20.000   \n",
      "...              ...        ...         ...       ...       ...       ...   \n",
      "2025-12-27       NaN        NaN         NaN       NaN       NaN       NaN   \n",
      "2025-12-28       NaN        NaN         NaN       NaN       NaN       NaN   \n",
      "2025-12-29       NaN        NaN         NaN       NaN       NaN       NaN   \n",
      "2025-12-30       NaN        NaN         NaN       NaN       NaN       NaN   \n",
      "2025-12-31       NaN        NaN         NaN       NaN       NaN       NaN   \n",
      "\n",
      "            WSP_max   SD1_mean    WDR_mean  heavy_vehicle  light_vehicle  \\\n",
      "2024-10-22    5.481  22.588208  190.263208     867.083313   13832.472656   \n",
      "2024-10-23    5.481  22.588208  190.263208     896.904053   13134.101562   \n",
      "2024-10-24    5.560  22.588208  202.500000     943.933533   12655.133789   \n",
      "2024-10-25    5.560  22.588208  180.000000     995.617676   12486.125000   \n",
      "2024-10-26    5.560  22.588208  202.500000    1038.634033   12622.653320   \n",
      "...             ...        ...         ...            ...            ...   \n",
      "2025-12-27      NaN        NaN         NaN            NaN            NaN   \n",
      "2025-12-28      NaN        NaN         NaN            NaN            NaN   \n",
      "2025-12-29      NaN        NaN         NaN            NaN            NaN   \n",
      "2025-12-30      NaN        NaN         NaN            NaN            NaN   \n",
      "2025-12-31      NaN        NaN         NaN            NaN            NaN   \n",
      "\n",
      "            public_holiday  school_holiday  \\\n",
      "2024-10-22             0.0             0.0   \n",
      "2024-10-23             0.0             0.0   \n",
      "2024-10-24             0.0             0.0   \n",
      "2024-10-25             0.0             0.0   \n",
      "2024-10-26             0.0             0.0   \n",
      "...                    ...             ...   \n",
      "2025-12-27             0.0             1.0   \n",
      "2025-12-28             0.0             1.0   \n",
      "2025-12-29             0.0             1.0   \n",
      "2025-12-30             0.0             1.0   \n",
      "2025-12-31             0.0             1.0   \n",
      "\n",
      "                                                     forecast  \n",
      "2024-10-22                                Clear. Light winds.  \n",
      "2024-10-23  Mostly sunny morning. The chance of fog in the...  \n",
      "2024-10-24  Partly cloudy. High chance of showers, most li...  \n",
      "2024-10-25  Partly cloudy. Medium chance of showers. Winds...  \n",
      "2024-10-26  Partly cloudy. Slight chance of a shower in th...  \n",
      "...                                                       ...  \n",
      "2025-12-27                                                NaN  \n",
      "2025-12-28                                                NaN  \n",
      "2025-12-29                                                NaN  \n",
      "2025-12-30                                                NaN  \n",
      "2025-12-31                                                NaN  \n",
      "\n",
      "[436 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the trained model and scalers\n",
    "model = load_model(\"lstm_air_quality_model.h5\")\n",
    "scaler_features = np.load(\"scaler_features.npy\", allow_pickle=True).item()\n",
    "scaler_target = np.load(\"scaler_target.npy\", allow_pickle=True).item()\n",
    "\n",
    "# Rolling forecast function\n",
    "def rolling_forecast(model, initial_sequence, n_days, scaler_features, scaler_target):\n",
    "    rolling_predictions = []\n",
    "    current_sequence = initial_sequence  # Start with the most recent sequence\n",
    "\n",
    "    for _ in range(n_days):\n",
    "        pred = model.predict(np.array([current_sequence]))[0]  # Predict on the current sequence\n",
    "        rolling_predictions.append(pred)\n",
    "\n",
    "        # Reshape the prediction to ensure it has compatible dimensions for concatenation\n",
    "        pred_reshaped = pred[:len(features)].reshape(1, -1)  # Reshape prediction to 2D\n",
    "\n",
    "        # Append the prediction to the sequence and remove the oldest time step\n",
    "        next_input = np.vstack([current_sequence[1:], pred_reshaped])\n",
    "        current_sequence = next_input\n",
    "\n",
    "    rolling_predictions = np.array(rolling_predictions)\n",
    "    return scaler_target.inverse_transform(rolling_predictions)  # Inverse transform the predictions\n",
    "\n",
    "# Step 1: Prepare for rolling predictions (using the last valid sequence)\n",
    "last_sequence = combined_data_scaled.iloc[first_missing_loc-sequence_length:first_missing_loc][features].values\n",
    "\n",
    "# Perform the rolling forecast for 8 days\n",
    "rolling_predictions = rolling_forecast(model, last_sequence, 8, scaler_features, scaler_target)\n",
    "\n",
    "# Step 2: Create a DataFrame with the rolling predictions\n",
    "predicted_dates = pd.date_range(start=first_missing_index, periods=8)\n",
    "predicted_values_df = pd.DataFrame(rolling_predictions, columns=target, index=predicted_dates)\n",
    "\n",
    "# Step 3: Update the original combined_data DataFrame with the rolling predictions\n",
    "combined_data.update(predicted_values_df)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(combined_data.loc[first_missing_index:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec33cd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/br/kn0p5yrn6d771z_m2v7qll780000gp/T/ipykernel_73596/1095795949.py:20: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the parameter you want to visualize (e.g., 'CO_mean')\n",
    "parameter = 'PM10_mean'\n",
    "\n",
    "# Assuming 'predicted_values_df' contains the predicted values in a DataFrame, with the same index as 'combined_data'\n",
    "# Plot the actual values over time\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(combined_data.index, combined_data[parameter], label=f'Actual {parameter}', color='b')\n",
    "\n",
    "# Plot the predicted values over time (in a different color)\n",
    "plt.plot(predicted_values_df.index, predicted_values_df[parameter], label=f'Predicted {parameter}', color='r', linestyle='--')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(f'Actual vs Predicted {parameter}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(parameter)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a71f526d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/br/kn0p5yrn6d771z_m2v7qll780000gp/T/ipykernel_73596/2804863000.py:27: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Define the parameter you want to visualize (e.g., 'PM10_mean')\n",
    "parameter = 'PM10_mean'\n",
    "\n",
    "# Define the start and end dates for zooming in (last 180 days before the first predicted date)\n",
    "zoom_start_date = predicted_values_df.index[0] - pd.Timedelta(days=180)\n",
    "zoom_end_date = predicted_values_df.index[-1]  # Include the prediction period\n",
    "\n",
    "# Filter the actual values for the 180 days before the prediction\n",
    "actual_zoomed = combined_data.loc[zoom_start_date:zoom_end_date]\n",
    "\n",
    "# Plot the actual values over the zoomed-in time period\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(actual_zoomed.index, actual_zoomed[parameter], label=f'Actual {parameter}', color='b')\n",
    "\n",
    "# Plot the predicted values over the same time period\n",
    "plt.plot(predicted_values_df.index, predicted_values_df[parameter], label=f'Predicted {parameter}', color='r', linestyle='--')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(f'Actual vs Predicted {parameter} (Zoomed: Last 180 Days + Prediction)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(parameter)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04e7df2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CO_mean               0.204301\n",
       "HUMID_mean           64.559833\n",
       "NEPH_mean             0.134583\n",
       "NO_mean              -0.024596\n",
       "NO2_mean              0.125475\n",
       "OZONE_mean            2.594704\n",
       "SO2_mean              0.004076\n",
       "PM10_mean            15.873292\n",
       "PM2.5_mean            3.896208\n",
       "RAIN_sum                   0.0\n",
       "TEMP_min                15.838\n",
       "TEMP_max                19.424\n",
       "WSP_max                  5.481\n",
       "SD1_mean             22.588208\n",
       "WDR_mean            190.263208\n",
       "heavy_vehicle       860.453613\n",
       "light_vehicle     14591.889648\n",
       "public_holiday             0.0\n",
       "school_holiday             0.0\n",
       "forecast                   NaN\n",
       "Name: 2024-10-21 00:00:00, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.loc['2024-10-21']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacdee79",
   "metadata": {},
   "source": [
    "# Categorise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4b39e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to categorize based on the pollutant dictionary\n",
    "def categorize_value(value, pollutant):\n",
    "    for category, (low, high) in pollutant_categories[pollutant].items():\n",
    "        if low <= value < high:\n",
    "            return category\n",
    "    return None\n",
    "\n",
    "# Example pollutant_categories dictionary\n",
    "pollutant_categories = {\n",
    "    'CO': {'Good': (0, 1), 'Fair': (1, 2), 'Poor': (2, 5), 'Very Poor': (5, float('inf'))},\n",
    "    'OZONE': {'Good': (0, 5.4), 'Fair': (5.5, 8), 'Poor': (8.1, 12), 'Very Poor': (12.1, float('inf'))},\n",
    "    'PM10': {'Good': (0, 50), 'Fair': (50, 100), 'Poor': (100, 150), 'Very Poor': (150, float('inf'))},\n",
    "    'PM2.5': {'Good': (0, 25), 'Fair': (25, 50), 'Poor': (50, 75), 'Very Poor': (75, float('inf'))},\n",
    "    'SO2': {'Good': (0, 13.3), 'Fair': (13.4, 20), 'Poor': (20.1, 30), 'Very Poor': (30.1, float('inf'))}\n",
    "}\n",
    "\n",
    "# Example pollutant_mapping dictionary\n",
    "pollutant_mapping = {\n",
    "    'CO_mean': 'CO',\n",
    "    'OZONE_mean': 'OZONE',\n",
    "    'PM10_mean': 'PM10',\n",
    "    'PM2.5_mean': 'PM2.5',\n",
    "    'SO2_mean': 'SO2'\n",
    "}\n",
    "\n",
    "pollutants = ['CO_mean', 'OZONE_mean', 'PM10_mean', 'PM2.5_mean', 'SO2_mean']\n",
    "\n",
    "\n",
    "# Assuming your DataFrame contains the columns 'CO_mean', 'OZONE_mean', etc.\n",
    "for pollutant in pollutants:\n",
    "    pollutant_key = pollutant_mapping[pollutant]  # Use the correct pollutant name in the dictionary\n",
    "    combined_data[f'{pollutant_key}'] = combined_data[pollutant].apply(lambda x: categorize_value(x, pollutant_key))\n",
    "\n",
    "# Function to find the worst category for each row\n",
    "def worst_category(row):\n",
    "    categories = row[[f'{pollutant_mapping[pollutant]}' for pollutant in pollutants]]\n",
    "    category_order = ['Very Poor', 'Poor', 'Fair', 'Good']\n",
    "    for cat in category_order:\n",
    "        if cat in categories.values:\n",
    "            return cat\n",
    "    return 'Good'\n",
    "\n",
    "# Get today's date\n",
    "today = pd.Timestamp.today().normalize()  # Normalize to get just the date (no time component)\n",
    "\n",
    "# Filter the DataFrame for today and the next 6 days (including today)\n",
    "next_7_days = combined_data[(combined_data.index >= today) & (combined_data.index < today + pd.Timedelta(days=7))].copy()\n",
    "\n",
    "# Apply the categorization for the next 7 days and create the 'overall' column\n",
    "next_7_days['overall'] = next_7_days.apply(worst_category, axis=1)\n",
    "\n",
    "# Check if the 'overall' column exists, if not, create it in combined_data\n",
    "if 'overall' not in combined_data.columns:\n",
    "    combined_data['overall'] = None\n",
    "\n",
    "# Merge the next 7 days back into the original DataFrame (including the 'overall' column)\n",
    "combined_data.update(next_7_days)\n",
    "\n",
    "# Ensure the new 'overall' column is properly added and displayed in the DataFrame\n",
    "combined_data.loc[next_7_days.index, 'overall'] = next_7_days['overall']\n",
    "\n",
    "# Display the result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e14ea",
   "metadata": {},
   "source": [
    "# For streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "861d0b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = pd.Timestamp.today().normalize()\n",
    "\n",
    "next_7_days = today + pd.Timedelta(days=6)\n",
    "\n",
    "week_data = combined_data.loc[(combined_data.index >= today) & (combined_data.index <= next_7_days)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41eabe20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO_mean</th>\n",
       "      <th>HUMID_mean</th>\n",
       "      <th>NEPH_mean</th>\n",
       "      <th>NO_mean</th>\n",
       "      <th>NO2_mean</th>\n",
       "      <th>OZONE_mean</th>\n",
       "      <th>SO2_mean</th>\n",
       "      <th>PM10_mean</th>\n",
       "      <th>PM2.5_mean</th>\n",
       "      <th>RAIN_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>light_vehicle</th>\n",
       "      <th>public_holiday</th>\n",
       "      <th>school_holiday</th>\n",
       "      <th>forecast</th>\n",
       "      <th>CO</th>\n",
       "      <th>OZONE</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>SO2</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-22</th>\n",
       "      <td>0.165748</td>\n",
       "      <td>64.559833</td>\n",
       "      <td>0.134583</td>\n",
       "      <td>0.230865</td>\n",
       "      <td>0.455354</td>\n",
       "      <td>1.728650</td>\n",
       "      <td>0.038801</td>\n",
       "      <td>12.688401</td>\n",
       "      <td>2.575596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13832.472656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clear. Light winds.</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-23</th>\n",
       "      <td>0.187882</td>\n",
       "      <td>64.559833</td>\n",
       "      <td>0.134583</td>\n",
       "      <td>0.547301</td>\n",
       "      <td>0.668562</td>\n",
       "      <td>1.514649</td>\n",
       "      <td>0.049858</td>\n",
       "      <td>11.142067</td>\n",
       "      <td>3.073559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13134.101562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mostly sunny morning. The chance of fog in the...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-24</th>\n",
       "      <td>0.208911</td>\n",
       "      <td>64.559833</td>\n",
       "      <td>0.134583</td>\n",
       "      <td>0.815310</td>\n",
       "      <td>0.874443</td>\n",
       "      <td>1.370425</td>\n",
       "      <td>0.066353</td>\n",
       "      <td>11.072093</td>\n",
       "      <td>3.793838</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12655.133789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partly cloudy. High chance of showers, most li...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-25</th>\n",
       "      <td>0.225088</td>\n",
       "      <td>64.559833</td>\n",
       "      <td>0.134583</td>\n",
       "      <td>1.000517</td>\n",
       "      <td>1.017205</td>\n",
       "      <td>1.252399</td>\n",
       "      <td>0.080411</td>\n",
       "      <td>11.480001</td>\n",
       "      <td>4.449006</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12486.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partly cloudy. Medium chance of showers. Winds...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-26</th>\n",
       "      <td>0.242674</td>\n",
       "      <td>64.559833</td>\n",
       "      <td>0.134583</td>\n",
       "      <td>1.047098</td>\n",
       "      <td>1.117258</td>\n",
       "      <td>1.296528</td>\n",
       "      <td>0.091702</td>\n",
       "      <td>12.157179</td>\n",
       "      <td>5.388426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12622.653320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partly cloudy. Slight chance of a shower in th...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-27</th>\n",
       "      <td>0.240510</td>\n",
       "      <td>64.559833</td>\n",
       "      <td>0.134583</td>\n",
       "      <td>0.994688</td>\n",
       "      <td>1.124879</td>\n",
       "      <td>1.421491</td>\n",
       "      <td>0.090879</td>\n",
       "      <td>11.108928</td>\n",
       "      <td>5.796731</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12996.993164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partly cloudy. Slight chance of a shower, most...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-28</th>\n",
       "      <td>0.244019</td>\n",
       "      <td>64.559833</td>\n",
       "      <td>0.134583</td>\n",
       "      <td>0.960204</td>\n",
       "      <td>1.147322</td>\n",
       "      <td>1.497956</td>\n",
       "      <td>0.083762</td>\n",
       "      <td>9.735151</td>\n",
       "      <td>6.300473</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13518.515625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Partly cloudy. Medium chance of showers. Winds...</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             CO_mean  HUMID_mean  NEPH_mean   NO_mean  NO2_mean  OZONE_mean  \\\n",
       "2024-10-22  0.165748   64.559833   0.134583  0.230865  0.455354    1.728650   \n",
       "2024-10-23  0.187882   64.559833   0.134583  0.547301  0.668562    1.514649   \n",
       "2024-10-24  0.208911   64.559833   0.134583  0.815310  0.874443    1.370425   \n",
       "2024-10-25  0.225088   64.559833   0.134583  1.000517  1.017205    1.252399   \n",
       "2024-10-26  0.242674   64.559833   0.134583  1.047098  1.117258    1.296528   \n",
       "2024-10-27  0.240510   64.559833   0.134583  0.994688  1.124879    1.421491   \n",
       "2024-10-28  0.244019   64.559833   0.134583  0.960204  1.147322    1.497956   \n",
       "\n",
       "            SO2_mean  PM10_mean  PM2.5_mean  RAIN_sum  ...  light_vehicle  \\\n",
       "2024-10-22  0.038801  12.688401    2.575596       0.0  ...   13832.472656   \n",
       "2024-10-23  0.049858  11.142067    3.073559       0.0  ...   13134.101562   \n",
       "2024-10-24  0.066353  11.072093    3.793838       9.0  ...   12655.133789   \n",
       "2024-10-25  0.080411  11.480001    4.449006       2.0  ...   12486.125000   \n",
       "2024-10-26  0.091702  12.157179    5.388426       1.0  ...   12622.653320   \n",
       "2024-10-27  0.090879  11.108928    5.796731       1.0  ...   12996.993164   \n",
       "2024-10-28  0.083762   9.735151    6.300473       2.0  ...   13518.515625   \n",
       "\n",
       "            public_holiday  school_holiday  \\\n",
       "2024-10-22             0.0             0.0   \n",
       "2024-10-23             0.0             0.0   \n",
       "2024-10-24             0.0             0.0   \n",
       "2024-10-25             0.0             0.0   \n",
       "2024-10-26             0.0             0.0   \n",
       "2024-10-27             0.0             0.0   \n",
       "2024-10-28             0.0             0.0   \n",
       "\n",
       "                                                     forecast    CO  OZONE  \\\n",
       "2024-10-22                                Clear. Light winds.  Good   Good   \n",
       "2024-10-23  Mostly sunny morning. The chance of fog in the...  Good   Good   \n",
       "2024-10-24  Partly cloudy. High chance of showers, most li...  Good   Good   \n",
       "2024-10-25  Partly cloudy. Medium chance of showers. Winds...  Good   Good   \n",
       "2024-10-26  Partly cloudy. Slight chance of a shower in th...  Good   Good   \n",
       "2024-10-27  Partly cloudy. Slight chance of a shower, most...  Good   Good   \n",
       "2024-10-28  Partly cloudy. Medium chance of showers. Winds...  Good   Good   \n",
       "\n",
       "            PM10  PM2.5   SO2 overall  \n",
       "2024-10-22  Good   Good  Good    Good  \n",
       "2024-10-23  Good   Good  Good    Good  \n",
       "2024-10-24  Good   Good  Good    Good  \n",
       "2024-10-25  Good   Good  Good    Good  \n",
       "2024-10-26  Good   Good  Good    Good  \n",
       "2024-10-27  Good   Good  Good    Good  \n",
       "2024-10-28  Good   Good  Good    Good  \n",
       "\n",
       "[7 rows x 26 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3590bcce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f692d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit app: Sydney Air Quality Forecast\n",
    "st.title(\"Sydney Air Quality Forecast\")\n",
    "st.subheader(\"Weather\")\n",
    "\n",
    "# Show Weather Data (TEMP_min, TEMP_max, RAIN_sum, forecast)\n",
    "weather_columns = ['TEMP_min', 'TEMP_max', 'RAIN_sum', 'forecast']\n",
    "st.write(week_data[weather_columns])\n",
    "\n",
    "# Air Quality Subtitle\n",
    "st.subheader(\"Air Quality\")\n",
    "\n",
    "# Function for color coding air quality\n",
    "def color_air_quality(val):\n",
    "    color = ''\n",
    "    if val == 'Good':\n",
    "        color = 'background-color: green'\n",
    "    elif val == 'Fair':\n",
    "        color = 'background-color: yellow'\n",
    "    elif val == 'Poor':\n",
    "        color = 'background-color: orange'\n",
    "    elif val == 'Very Poor':\n",
    "        color = 'background-color: red'\n",
    "    return color\n",
    "\n",
    "# Select the air quality columns to display\n",
    "air_quality_columns = ['CO', 'OZONE', 'PM10', 'PM2.5', 'SO2', 'overall']\n",
    "\n",
    "# Apply the color formatting\n",
    "styled_df = week_data[air_quality_columns].style.applymap(color_air_quality)\n",
    "\n",
    "# Display the styled DataFrame in Streamlit\n",
    "st.write(styled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097cb915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
